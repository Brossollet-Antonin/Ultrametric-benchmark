{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrametric benchmark for continual learning - Artificial sequence - Data analysis, averaging across trials per condition\n",
    "#### Simon Lebastard - 01/11/2020\n",
    "\n",
    "First off let's go to the directory where the latest data was stored for artificial_8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_root = '/home/proprietaire/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root)\n",
    "from result_loader import ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'artificial_32'\n",
    "nnarchi = 'FCL20'\n",
    "seq_length = 20000\n",
    "n_batches = 10\n",
    "seq_genr_type = 'twofold_split'\n",
    "\n",
    "# Foar artificial ultrametric dataset only\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "artificial_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+'/Results')\n",
    "\n",
    "dataroot = project_root+'/Results/' + dataset + '/' + nnarchi + '/' + seq_genr_type + '_length' + str(seq_length)+'_batches'+str(n_batches)\n",
    "if 'artificial' in dataset:\n",
    "    dataroot += '_seqlen'+str(artificial_seq_len)+'_ratio'+str(linear_ratio_for_artificial_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_8 datapaths\n",
    "datapaths = {\n",
    "    ('artificial_8', 'CNN', 'temporal_correlation', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200113_20591578945581',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200113_21261578947211',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200113_21531578948799',\n",
    "        (0.40, 10): 'T0.400_Memory0_block10_200113_21071578946032',\n",
    "        (0.40, 100): 'T0.400_Memory0_block100_200113_21361578947778',\n",
    "        (0.40, 1000): 'T0.400_Memory0_block1000_200113_22011578949298',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200113_21171578946647',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200113_21451578948317',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200113_22101578949858'\n",
    "    },\n",
    "    ('artificial_8', 'FCL6', 'uniform', 'ratio_5'): {#lr 0.01 \n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.15, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 1000): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 1000): 'T0.150_Memory0_block10_200116_232209'\n",
    "    },\n",
    "    ('artificial_8', 'FCL10', 'uniform', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.15, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.40, 1000): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 10): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 100): 'T0.150_Memory0_block10_200116_232209',\n",
    "        (0.65, 1000): 'T0.150_Memory0_block10_200116_232209'\n",
    "    },\n",
    "    ('artificial_8', 'FCL20', 'uniform', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.15, 100): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.40, 10): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.40, 100): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.40, 1000): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.65, 10): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.65, 100): 'T0.150_Memory0_block10_200116_225307',\n",
    "        (0.65, 1000): 'T0.150_Memory0_block10_200116_225307'\n",
    "    },\n",
    "    ('artificial_8', 'CNN', 'onefold_split', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200114_20141579029267',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200114_20421579030940',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200114_21171579033036',\n",
    "        (0.40, 10): 'T0.400_Memory0_block10_200114_20261579030000',\n",
    "        (0.40, 100): 'T0.400_Memory0_block100_200114_20541579031648',\n",
    "        (0.40, 1000): 'T0.400_Memory0_block1000_200114_21291579033774',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200114_20341579030466',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200114_21061579032367',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200114_21381579034301'\n",
    "    },\n",
    "     ('artificial_8', 'CNN', 'twofold_split', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200113_22571578952645',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200114_01361578962218',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200114_02171578964665',\n",
    "        (0.40, 10): 'T0.400_Memory0_block10_200113_23051578953127',\n",
    "        (0.40, 100): 'T0.400_Memory0_block100_200114_01431578962639',\n",
    "        (0.40, 1000): 'T0.400_Memory0_block1000_200114_02271578965236',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200113_23131578953628',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200114_02081578964107',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200114_02391578965965'\n",
    "    },\n",
    "    ('artificial_16', 'CNN', 'temporal_correlation', 'ratio_1'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200112_22211578864068',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200112_23051578866751',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200112_23541578869670',\n",
    "        (0.4, 10): 'T0.400_Memory0_block10_200112_22351578864916',\n",
    "        (0.4, 100): 'T0.400_Memory0_block100_200112_23211578867661',\n",
    "        (0.4, 1000): 'T0.400_Memory0_block1000_200113_00101578870650',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200112_22501578865859',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200112_23371578868671',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200113_00331578872009'\n",
    "    },\n",
    "    ('artificial_32', 'FCL6', 'temporal_correlation', 'ratio_8'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200117_195604',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200117_221949',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200117_223529',\n",
    "        (0.4, 10): 'T0.400_Memory0_block10_200117_190113',\n",
    "        (0.4, 100): 'T0.400_Memory0_block100_200117_191751',\n",
    "        (0.4, 1000): 'T0.400_Memory0_block1000_200117_193308',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200117_202532',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200117_204307',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200117_205940'\n",
    "    },\n",
    "    ('artificial_1024', 'CNN', 'temporal_correlation', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): 'T0.150_Memory0_block10_200115_18121579108346',\n",
    "        (0.15, 100): 'T0.150_Memory0_block100_200115_15031579118601',\n",
    "        (0.15, 1000): 'T0.150_Memory0_block1000_200115_12541579110877',\n",
    "        (0.4, 10): 'T0.400_Memory0_block10_200115_20201579116049',\n",
    "        (0.4, 100): 'T0.400_Memory0_block100_200115_18141579130057',\n",
    "        (0.4, 1000): 'T0.400_Memory0_block1000_200115_14411579117303',\n",
    "        (0.65, 10): 'T0.650_Memory0_block10_200115_22221579123326',\n",
    "        (0.65, 100): 'T0.650_Memory0_block100_200116_00241579130655',\n",
    "        (0.65, 1000): 'T0.650_Memory0_block1000_200115_17151579126537'\n",
    "    },\n",
    "    ('artificial_32', 'FCL20', 'twofold_split'): { #lr 0.05\n",
    "        (0.40, 100): 'T0.400_Memory0_block100_200124_233400'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll loop through the files produced by the ultrametric framework accross temperatures and shuffle block size, and construct dictionnaries indexed by [T, blocksz].\n",
    "We will then use those dicts to create the plots for DARPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load standard packages and find out about the content of each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.4, 100): 'T0.400_Memory0_block100_200124_233400'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapaths[(dataset, nnarchi, seq_genr_type, 'ratio_'+str(linear_ratio_for_artificial_seq))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/proprietaire/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark/Results/artificial_32/FCL20/twofold_split_length20000_batches10_seqlen200_ratio8/T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-817147071592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnarchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_genr_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ratio_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_ratio_for_artificial_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark/result_loader.py\u001b[0m in \u001b[0;36mload_analytics\u001b[0;34m(self, load_data, load_atc, load_shuffle)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatapath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_labels_orig.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/proprietaire/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark/Results/artificial_32/FCL20/twofold_split_length20000_batches10_seqlen200_ratio8/T'"
     ]
    }
   ],
   "source": [
    "rs = ResultSet(dataroot, datapaths[(dataset, nnarchi, seq_genr_type, 'ratio_'+str(linear_ratio_for_artificial_seq))])\n",
    "rs.load_analytics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a posteriori)\n",
    "\n",
    "Let's plot the autocorrelation function to DARPA standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_l = 2**5\n",
    "maxh = 2**19    \n",
    "block_sizes = [1, 10, 100, 1000]\n",
    "n_tests = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def make_ohe(y, n_labels):\n",
    "    ohe = np.zeros((len(y), n_labels))    \n",
    "    ohe[np.arange(len(y)),y] = 1\n",
    "    return ohe\n",
    "\n",
    "def sequence_autocor(lbl_sequence, n_labels, nlags=200, fft=True):\n",
    "    length = len(lbl_sequence)\n",
    "    lbl_ohe = make_ohe(lbl_sequence, n_labels)\n",
    "    autocor = np.zeros(nlags)\n",
    "    \n",
    "    for lbl in range(n_labels):\n",
    "        autocor_lbl = acf(\n",
    "            lbl_ohe[:,lbl].tolist(),\n",
    "            unbiased=True,\n",
    "            nlags=nlags-1, #number of time points to evaluate autocorrelation for\n",
    "            qstat=False, # allows to return the Ljung-Box q statistic\n",
    "            fft=fft, # this is the fastest method, but impact on accuracy should be assessed when possible\n",
    "            alpha=None # allows to compute confidence intervals\n",
    "            )\n",
    "        autocor = autocor + np.asarray(autocor_lbl)\n",
    "    return autocor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = rs.train_labels_orig[(0.65, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc = sequence_autocor(seq, nlags=500, 0n_labels=1024, fft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def shuffleblocks(seq, block_sz, snbr):\n",
    "    lseq = len(seq)\n",
    "    copied_seq = deepcopy(seq)\n",
    "    sseq = []   # Will contain the shuffled sequence\n",
    "    for k in range(snbr):\n",
    "        begin, end = int(k*lseq/snbr), int((k+1)*lseq/snbr)\n",
    "        bbegin, bend = int(begin/block_sz), int(end/block_sz)\n",
    "        block_indices = [i for i in range(len(seq[:end])//block_sz)]\n",
    "        random.shuffle(block_indices)\n",
    "        for i in block_indices[bbegin:bend]:\n",
    "            sseq += copied_seq[i*block_sz:(i+1)*block_sz]\n",
    "    return sseq \n",
    "\n",
    "def get_atc(seq, blocks, snbr, T):\n",
    "    tree_l = max(seq)+1\n",
    "    plt.figure(1, figsize=(18,10))\n",
    "    hlocs_stat = np.zeros(maxh-1)\n",
    "    \n",
    "    for i in range(tree_l):\n",
    "        locs = np.array([j for j in range(len(seq)) if seq[j]==i])\n",
    "        locss = deepcopy(locs)\n",
    "        locss[:-1] = locss[1:]\n",
    "        locsd = locss-locs\n",
    "        bins = range(maxh)\n",
    "        hlocs = np.histogram(locsd, bins, density=True)\n",
    "        hlocs_stat = hlocs_stat + hlocs[0]/tree_l\n",
    "        \n",
    "    plt.loglog(\n",
    "        bins[:-1],\n",
    "        hlocs_stat,\n",
    "        marker='.',\n",
    "        ls = 'none',\n",
    "        label='T={0:.2f} - Original sequence'.format(T)\n",
    "    ) \n",
    "    for nfig, block_sz in enumerate(blocks):\n",
    "        hlocs_stat = np.zeros(maxh-1)\n",
    "        shuffleseq = shuffleblocks(seq, block_sz, snbr)\n",
    "        #plt.figure(nfig+2)\n",
    "        #plt.plot(shuffleseq)\n",
    "        #plt.title(block_sz)\n",
    "        for i in range(tree_l):\n",
    "            locs = np.array([j for j in range(len(shuffleseq)) if shuffleseq[j]==i])\n",
    "            locss = deepcopy(locs)\n",
    "            locss[:-1] = locss[1:]\n",
    "            locsd = locss-locs\n",
    "            bins = range(maxh)\n",
    "            hlocs = np.histogram(locsd, bins, density=True)\n",
    "            hlocs_stat = hlocs_stat + hlocs[0]/tree_l\n",
    "            \n",
    "        plt.figure(1)    \n",
    "        plt.loglog(\n",
    "            bins[:-1],\n",
    "            hlocs_stat,\n",
    "            marker = '+',\n",
    "            ls = 'none',\n",
    "            label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(T, block_sz),\n",
    "            alpha=0.5) \n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_atc(rs.train_labels_orig[(0.15, 10)], block_sizes, n_tests, T=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.atc_orig.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "atc_fig = plt.figure(figsize=(14,2*9))\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "n_omits = 30\n",
    "markers = ['o','+','x']\n",
    "\n",
    "atc_ax = plt.subplot(211)\n",
    "\n",
    "params = (0.4, 10)\n",
    "atc_orig = rs.atc_orig[params][n_omits:]\n",
    "atc_ax.plot(\n",
    "        atc_orig,\n",
    "        marker='.',\n",
    "        markersize=10,\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "for k, params in enumerate([(0.4, 10), (0.4, 100), (0.4, 1000)]):\n",
    "\n",
    "    hsv_shfl = tuple([0.6, 1-k*0.2, 0.5+k*0.15]) \n",
    "    \n",
    "    # Discard the first few data points\n",
    "    \n",
    "    atc_shfl = rs.atc_shfl[params][-1][n_omits:]\n",
    "\n",
    "    atc_ax.plot(\n",
    "        atc_shfl,\n",
    "        marker=markers[k],\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shufled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "    \n",
    "plt.title('Autocorrelation function for original and shuffled sequences')\n",
    "atc_ax.legend()\n",
    "\n",
    "\n",
    "atc_ax = plt.subplot(212)\n",
    "\n",
    "params = (0.65, 10)\n",
    "atc_orig = rs.atc_orig[params][n_omits:]\n",
    "atc_ax.plot(\n",
    "        atc_orig,\n",
    "        marker='.',\n",
    "        markersize = 10,\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "for k, params in enumerate([(0.65, 10), (0.65, 100), (0.65, 1000)]):\n",
    "\n",
    "    hsv_shfl = tuple([0.6, 1-k*0.2, 0.5+k*0.15])\n",
    "    \n",
    "    # Discard the first few data points\n",
    "    \n",
    "    atc_shfl = rs.atc_shfl[params][-1][n_omits:]\n",
    "\n",
    "    atc_ax.plot(\n",
    "        atc_shfl,\n",
    "        marker=markers[k],\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shufled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "    \n",
    "plt.title('Autocorrelation function for original and shuffled sequences')\n",
    "atc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fig = plt.figure(figsize=(18,2*9))\n",
    "\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x']\n",
    "\n",
    "\n",
    "acc_ax = plt.subplot(211)\n",
    "for param_id, params in enumerate([(0.4, 10), (0.4, 100), (0.4, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.2, 0.5+param_id*0.15])\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_orig[params][:,0],\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_shfl[params][:,0],\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences')\n",
    "acc_ax.legend()\n",
    "\n",
    "acc_ax = plt.subplot(313)\n",
    "for param_id, params in enumerate([(0.65, 10), (0.65, 100), (0.65, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.2, 0.5+param_id*0.15])\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_orig[params][:,0],\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_shfl[params][:,0],\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences')\n",
    "acc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of training labels along training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    #for params in list(rs.params.keys()):\n",
    "    for params in [(0.4, 1000)]:\n",
    "        total_seq_length = len(rs.train_labels_orig[params])\n",
    "        label_data = rs.train_labels_orig[params][:(hist_id+1)*(total_seq_length//n_hists)]\n",
    "    \n",
    "        acc_ax.hist(\n",
    "            label_data,\n",
    "            range = (0, 32),\n",
    "            density = True,\n",
    "            alpha = 0.5,\n",
    "            label = \"Distribution of sequence labels for T={0:.2f}\".format(params[0])\n",
    "        )\n",
    "        acc_ax.set_ylim(0, 0.3)\n",
    "        \n",
    "        acc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted class distribution as function of test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(param_tuple):\n",
    "\n",
    "    cls_dstr_fig = plt.figure(figsize=(18,18))\n",
    "\n",
    "    n_tests = int(rs.params[param_tuple][0][6])\n",
    "\n",
    "    for test_run_q in range(10): #rs.params['test_nbr'] or whatever\n",
    "\n",
    "        cls_dstr_ax = plt.subplot(5,2,test_run_q+1)\n",
    "\n",
    "        test_run_id = int((test_run_q/10)*n_tests)\n",
    "        cls_dstr_ax.bar(\n",
    "            [k - 0.2 for k in range(8)],\n",
    "            rs.var_pred_orig[params][test_run_id,0],\n",
    "            color = 'b',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        cls_dstr_ax.bar(\n",
    "            [k + 0.2 for k in range(8)],\n",
    "            rs.var_pred_shfl[params][test_run_id,0],\n",
    "            color = 'r',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        n_training_examples_seen = int(((test_run_id+1) / n_tests)*seq_length)\n",
    "        plt.title('Distribution of predicted classes within test batch after training on {0:d} examples'.format(n_training_examples_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_fig = plt.figure(figsize=(18,9*3))\n",
    "\n",
    "for param_id, params in enumerate([(0.15, 1000), (0.4, 1000), (0.65, 1000)]):\n",
    "    lbls_ax = plt.subplot(3,1,1+param_id)\n",
    "    lbls_ax.plot(rs.train_labels_orig[params])\n",
    "    ttl = 'History of labels in the original training sequence - T='+str(params[0])\n",
    "    plt.title(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
