{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrametric benchmark for continual learning - Artificial sequence - Data analysis, averaging across trials per condition\n",
    "#### Simon Lebastard - 01/11/2020\n",
    "\n",
    "First off let's go to the directory where the latest data was stored for artificial_8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_root = '/home/proprietaire/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root)\n",
    "from result_loader import ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'artificial_32'\n",
    "nnarchi = 'FCL20'\n",
    "seq_length = 20000\n",
    "n_batches = 10\n",
    "seq_genr_type = 'twofold_split'\n",
    "\n",
    "# Foar artificial ultrametric dataset only\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "artificial_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+'/Results')\n",
    "\n",
    "dataroot = project_root+'/Results/' + dataset + '/' + nnarchi + '/' + seq_genr_type + '_length' + str(seq_length)+'_batches'+str(n_batches)\n",
    "if 'artificial' in dataset:\n",
    "    dataroot += '_seqlen'+str(artificial_seq_len)+'_ratio'+str(linear_ratio_for_artificial_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_8 datapaths\n",
    "datapaths = {\n",
    "    ('artificial_8', 'CNN', 'temporal_correlation', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200113_20591578945581'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200113_21261578947211'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200113_21531578948799'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200113_21071578946032'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200113_21361578947778'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200113_22011578949298'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200113_21171578946647'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200113_21451578948317'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200113_22101578949858'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_8', 'FCL6', 'uniform', 'ratio_5'): {#lr 0.01 \n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_8', 'FCL10', 'uniform', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_232209'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_8', 'FCL20', 'uniform', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block10_200116_225307'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_8', 'CNN', 'onefold_split', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200114_20141579029267'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200114_20421579030940'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200114_21171579033036'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200114_20261579030000'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200114_20541579031648'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200114_21291579033774'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200114_20341579030466'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200114_21061579032367'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200114_21381579034301'\n",
    "\t\t\t]\n",
    "    },\n",
    "     ('artificial_8', 'CNN', 'twofold_split', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200113_22571578952645'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200114_01361578962218'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200114_02171578964665'\n",
    "\t\t\t],\n",
    "        (0.40, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200113_23051578953127'\n",
    "\t\t\t],\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200114_01431578962639'\n",
    "\t\t\t],\n",
    "        (0.40, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200114_02271578965236'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200113_23131578953628'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200114_02081578964107'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200114_02391578965965'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_16', 'CNN', 'temporal_correlation', 'ratio_1'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200112_22211578864068'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200112_23051578866751'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200112_23541578869670'\n",
    "\t\t\t],\n",
    "        (0.4, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200112_22351578864916'\n",
    "\t\t\t],\n",
    "        (0.4, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200112_23211578867661'\n",
    "\t\t\t],\n",
    "        (0.4, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200113_00101578870650'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200112_22501578865859'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200112_23371578868671'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200113_00331578872009'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_32', 'FCL6', 'temporal_correlation', 'ratio_8'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200117_195604'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200117_221949'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200117_223529'\n",
    "\t\t\t],\n",
    "        (0.4, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200117_190113'\n",
    "\t\t\t],\n",
    "        (0.4, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200117_191751'\n",
    "\t\t\t],\n",
    "        (0.4, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200117_193308'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200117_202532'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200117_204307'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200117_205940'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_1024', 'CNN', 'temporal_correlation', 'ratio_5'): { #lr 0.01\n",
    "        (0.15, 10): [\n",
    "\t\t\t'T0.150_Memory0_block10_200115_18121579108346'\n",
    "\t\t\t],\n",
    "        (0.15, 100): [\n",
    "\t\t\t'T0.150_Memory0_block100_200115_15031579118601'\n",
    "\t\t\t],\n",
    "        (0.15, 1000): [\n",
    "\t\t\t'T0.150_Memory0_block1000_200115_12541579110877'\n",
    "\t\t\t],\n",
    "        (0.4, 10): [\n",
    "\t\t\t'T0.400_Memory0_block10_200115_20201579116049'\n",
    "\t\t\t],\n",
    "        (0.4, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200115_18141579130057'\n",
    "\t\t\t],\n",
    "        (0.4, 1000): [\n",
    "\t\t\t'T0.400_Memory0_block1000_200115_14411579117303'\n",
    "\t\t\t],\n",
    "        (0.65, 10): [\n",
    "\t\t\t'T0.650_Memory0_block10_200115_22221579123326'\n",
    "\t\t\t],\n",
    "        (0.65, 100): [\n",
    "\t\t\t'T0.650_Memory0_block100_200116_00241579130655'\n",
    "\t\t\t],\n",
    "        (0.65, 1000): [\n",
    "\t\t\t'T0.650_Memory0_block1000_200115_17151579126537'\n",
    "\t\t\t]\n",
    "    },\n",
    "    ('artificial_32', 'FCL20', 'twofold_split', 'ratio_8'): { #lr 0.05\n",
    "        (0.40, 100): [\n",
    "\t\t\t'T0.400_Memory0_block100_200124_233400'\n",
    "\t\t\t]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll loop through the files produced by the ultrametric framework accross temperatures and shuffle block size, and construct dictionnaries indexed by [T, blocksz].\n",
    "We will then use those dicts to create the plots for DARPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load standard packages and find out about the content of each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.4, 100): ['T0.400_Memory0_block100_200124_233400']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapaths[(dataset, nnarchi, seq_genr_type, 'ratio_'+str(linear_ratio_for_artificial_seq))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n"
     ]
    }
   ],
   "source": [
    "rs = ResultSet(dataroot, datapaths[(dataset, nnarchi, seq_genr_type, 'ratio_'+str(linear_ratio_for_artificial_seq))])\n",
    "rs.load_analytics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a posteriori)\n",
    "\n",
    "Let's plot the autocorrelation function to DARPA standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_l = 2**5\n",
    "maxh = 2**19    \n",
    "block_sizes = [1, 10, 100, 1000]\n",
    "n_tests = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def make_ohe(y, n_labels):\n",
    "    ohe = np.zeros((len(y), n_labels))    \n",
    "    ohe[np.arange(len(y)),y] = 1\n",
    "    return ohe\n",
    "\n",
    "def sequence_autocor(lbl_sequence, n_labels, nlags=200, fft=True):\n",
    "    length = len(lbl_sequence)\n",
    "    lbl_ohe = make_ohe(lbl_sequence, n_labels)\n",
    "    autocor = np.zeros(nlags)\n",
    "    \n",
    "    for lbl in range(n_labels):\n",
    "        autocor_lbl = acf(\n",
    "            lbl_ohe[:,lbl].tolist(),\n",
    "            unbiased=True,\n",
    "            nlags=nlags-1, #number of time points to evaluate autocorrelation for\n",
    "            qstat=False, # allows to return the Ljung-Box q statistic\n",
    "            fft=fft, # this is the fastest method, but impact on accuracy should be assessed when possible\n",
    "            alpha=None # allows to compute confidence intervals\n",
    "            )\n",
    "        autocor = autocor + np.asarray(autocor_lbl)\n",
    "    return autocor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = rs.train_labels_orig[(0.65, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc = sequence_autocor(seq, nlags=500, 0n_labels=1024, fft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def shuffleblocks(seq, block_sz, snbr):\n",
    "    lseq = len(seq)\n",
    "    copied_seq = deepcopy(seq)\n",
    "    sseq = []   # Will contain the shuffled sequence\n",
    "    for k in range(snbr):\n",
    "        begin, end = int(k*lseq/snbr), int((k+1)*lseq/snbr)\n",
    "        bbegin, bend = int(begin/block_sz), int(end/block_sz)\n",
    "        block_indices = [i for i in range(len(seq[:end])//block_sz)]\n",
    "        random.shuffle(block_indices)\n",
    "        for i in block_indices[bbegin:bend]:\n",
    "            sseq += copied_seq[i*block_sz:(i+1)*block_sz]\n",
    "    return sseq \n",
    "\n",
    "def get_atc(seq, blocks, snbr, T):\n",
    "    tree_l = max(seq)+1\n",
    "    plt.figure(1, figsize=(18,10))\n",
    "    hlocs_stat = np.zeros(maxh-1)\n",
    "    \n",
    "    for i in range(tree_l):\n",
    "        locs = np.array([j for j in range(len(seq)) if seq[j]==i])\n",
    "        locss = deepcopy(locs)\n",
    "        locss[:-1] = locss[1:]\n",
    "        locsd = locss-locs\n",
    "        bins = range(maxh)\n",
    "        hlocs = np.histogram(locsd, bins, density=True)\n",
    "        hlocs_stat = hlocs_stat + hlocs[0]/tree_l\n",
    "        \n",
    "    plt.loglog(\n",
    "        bins[:-1],\n",
    "        hlocs_stat,\n",
    "        marker='.',\n",
    "        ls = 'none',\n",
    "        label='T={0:.2f} - Original sequence'.format(T)\n",
    "    ) \n",
    "    for nfig, block_sz in enumerate(blocks):\n",
    "        hlocs_stat = np.zeros(maxh-1)\n",
    "        shuffleseq = shuffleblocks(seq, block_sz, snbr)\n",
    "        #plt.figure(nfig+2)\n",
    "        #plt.plot(shuffleseq)\n",
    "        #plt.title(block_sz)\n",
    "        for i in range(tree_l):\n",
    "            locs = np.array([j for j in range(len(shuffleseq)) if shuffleseq[j]==i])\n",
    "            locss = deepcopy(locs)\n",
    "            locss[:-1] = locss[1:]\n",
    "            locsd = locss-locs\n",
    "            bins = range(maxh)\n",
    "            hlocs = np.histogram(locsd, bins, density=True)\n",
    "            hlocs_stat = hlocs_stat + hlocs[0]/tree_l\n",
    "            \n",
    "        plt.figure(1)    \n",
    "        plt.loglog(\n",
    "            bins[:-1],\n",
    "            hlocs_stat,\n",
    "            marker = '+',\n",
    "            ls = 'none',\n",
    "            label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(T, block_sz),\n",
    "            alpha=0.5) \n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6953d42a2757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_atc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-d0551a2e059d>\u001b[0m in \u001b[0;36mget_atc\u001b[0;34m(seq, blocks, snbr, T)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_atc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtree_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mhlocs_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "get_atc(rs.train_labels_orig[(0.4, 100)], block_sizes, n_tests, T=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.atc_orig.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "atc_fig = plt.figure(figsize=(14,2*9))\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "n_omits = 30\n",
    "markers = ['o','+','x']\n",
    "\n",
    "atc_ax = plt.subplot(211)\n",
    "\n",
    "params = (0.4, 10)\n",
    "atc_orig = rs.atc_orig[params][n_omits:]\n",
    "atc_ax.plot(\n",
    "        atc_orig,\n",
    "        marker='.',\n",
    "        markersize=10,\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "for k, params in enumerate([(0.4, 10), (0.4, 100), (0.4, 1000)]):\n",
    "\n",
    "    hsv_shfl = tuple([0.6, 1-k*0.2, 0.5+k*0.15]) \n",
    "    \n",
    "    # Discard the first few data points\n",
    "    \n",
    "    atc_shfl = rs.atc_shfl[params][-1][n_omits:]\n",
    "\n",
    "    atc_ax.plot(\n",
    "        atc_shfl,\n",
    "        marker=markers[k],\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shufled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "    \n",
    "plt.title('Autocorrelation function for original and shuffled sequences')\n",
    "atc_ax.legend()\n",
    "\n",
    "\n",
    "atc_ax = plt.subplot(212)\n",
    "\n",
    "params = (0.65, 10)\n",
    "atc_orig = rs.atc_orig[params][n_omits:]\n",
    "atc_ax.plot(\n",
    "        atc_orig,\n",
    "        marker='.',\n",
    "        markersize = 10,\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "for k, params in enumerate([(0.65, 10), (0.65, 100), (0.65, 1000)]):\n",
    "\n",
    "    hsv_shfl = tuple([0.6, 1-k*0.2, 0.5+k*0.15])\n",
    "    \n",
    "    # Discard the first few data points\n",
    "    \n",
    "    atc_shfl = rs.atc_shfl[params][-1][n_omits:]\n",
    "\n",
    "    atc_ax.plot(\n",
    "        atc_shfl,\n",
    "        marker=markers[k],\n",
    "        ls='solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shufled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "    \n",
    "plt.title('Autocorrelation function for original and shuffled sequences')\n",
    "atc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fig = plt.figure(figsize=(18,2*9))\n",
    "\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x']\n",
    "\n",
    "\n",
    "acc_ax = plt.subplot(211)\n",
    "for param_id, params in enumerate([(0.4, 10), (0.4, 100), (0.4, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.2, 0.5+param_id*0.15])\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_orig[params][:,0],\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_shfl[params][:,0],\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences')\n",
    "acc_ax.legend()\n",
    "\n",
    "acc_ax = plt.subplot(313)\n",
    "for param_id, params in enumerate([(0.65, 10), (0.65, 100), (0.65, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.2, 0.5+param_id*0.15])\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_orig[params][:,0],\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Original sequence'.format(params[0], params[1])\n",
    "    )\n",
    "\n",
    "    acc_ax.plot(\n",
    "        rs.var_acc_shfl[params][:,0],\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences')\n",
    "acc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of training labels along training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    #for params in list(rs.params.keys()):\n",
    "    for params in [(0.4, 1000)]:\n",
    "        total_seq_length = len(rs.train_labels_orig[params])\n",
    "        label_data = rs.train_labels_orig[params][:(hist_id+1)*(total_seq_length//n_hists)]\n",
    "    \n",
    "        acc_ax.hist(\n",
    "            label_data,\n",
    "            range = (0, 32),\n",
    "            density = True,\n",
    "            alpha = 0.5,\n",
    "            label = \"Distribution of sequence labels for T={0:.2f}\".format(params[0])\n",
    "        )\n",
    "        acc_ax.set_ylim(0, 0.3)\n",
    "        \n",
    "        acc_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted class distribution as function of test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(param_tuple):\n",
    "\n",
    "    cls_dstr_fig = plt.figure(figsize=(18,18))\n",
    "\n",
    "    n_tests = int(rs.params[param_tuple][0][6])\n",
    "\n",
    "    for test_run_q in range(10): #rs.params['test_nbr'] or whatever\n",
    "\n",
    "        cls_dstr_ax = plt.subplot(5,2,test_run_q+1)\n",
    "\n",
    "        test_run_id = int((test_run_q/10)*n_tests)\n",
    "        cls_dstr_ax.bar(\n",
    "            [k - 0.2 for k in range(8)],\n",
    "            rs.var_pred_orig[params][test_run_id,0],\n",
    "            color = 'b',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        cls_dstr_ax.bar(\n",
    "            [k + 0.2 for k in range(8)],\n",
    "            rs.var_pred_shfl[params][test_run_id,0],\n",
    "            color = 'r',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        n_training_examples_seen = int(((test_run_id+1) / n_tests)*seq_length)\n",
    "        plt.title('Distribution of predicted classes within test batch after training on {0:d} examples'.format(n_training_examples_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.15, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rs.train_labels_orig[(0.4, 100)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbls_fig = plt.figure(figsize=(18,9))\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 100)]):\n",
    "    lbls_ax = plt.subplot(1,1,1+param_id)\n",
    "    lbls_ax.plot(rs.train_labels_orig[params][0])\n",
    "    ttl = 'History of labels in the original training sequence - T='+str(params[0])\n",
    "    plt.title(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
