{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrametric benchmark for continual learning - Artificial sequence - Data analysis\n",
    "#### Simon Lebastard - 01/11/2020\n",
    "\n",
    "First off let's go to the directory where the latest data was stored for artificial_8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to launch computation on random blocks sequences\n",
    "# python3 main.py -v --dataset artificial --data_tree_depth 5 --data_seq_size 200 --seqlength 200000 --seqtype random_blocks2 --split_length 1000  --nbrtest 200 --nnarchi FCL --hidden_sizes 20 -T 0.4 0.4 0.4 0.4 0.4 0.4 --blocksz 1 100 200 500 1000 2000 4000 6000 8000 10000 20000\n",
    "\n",
    "# Command to launch computation on ultrametric sequences\n",
    "# python3 main.py -v --dataset artificial --data_tree_depth 5 --data_seq_size 200 --seqlength 200000 --seqtype ultrametric --nbrtest 200 --nnarchi FCL --hidden_sizes 20 -T 0.4 0.4 0.4 0.4 0.4 0.4 --blocksz 1 100 200 500 1000 2000 4000 6000 8000 10000 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_root = '/home/slebastard-adc/Documents/Projects/ultrametric_benchmark/Ultrametric-Benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root)\n",
    "import result_loader as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'artificial_128'\n",
    "nnarchi = 'FCL50'\n",
    "seq_length = 300000\n",
    "n_tests = 300\n",
    "n_batches = 10\n",
    "seq_genr_type = 'ultrametric'\n",
    "lr=0.05\n",
    "\n",
    "# Foar artificial ultrametric dataset only\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "artificial_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "with open('Results/simu_mapping_compact.txt', 'r', encoding='utf-8') as filenames:\n",
    "    filenames_dct_txt = filenames.read().replace('\\n', '')\n",
    "    \n",
    "sim_directory = ast.literal_eval(filenames_dct_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll loop through the files produced by the ultrametric framework accross temperatures and shuffle block size, and construct dictionnaries indexed by [T, blocksz].\n",
    "We will then use those dicts to create the plots for DARPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load standard packages and find out about the content of each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+'/Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ld.ResultSet(\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataroot = project_root,\n",
    "    sim_struct = '1toM',\n",
    "    dataset_name = 'artificial_128',\n",
    "    nn_config = 'FCL50',\n",
    "    seq_type = 'ultrametric',\n",
    "    simset_id = 0.6\n",
    ")\n",
    "\n",
    "rs.load_analytics()\n",
    "\n",
    "## Uniform distr sequence ##\n",
    "\n",
    "rs_unif = ld.ResultSet(\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataroot = project_root,\n",
    "    sim_struct = '1toM',\n",
    "    dataset_name = 'artificial_128',\n",
    "    nn_config = 'FCL50',\n",
    "    seq_type = 'uniform',\n",
    "    simset_id = 0.0\n",
    ")\n",
    "rs_unif.load_analytics(load_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random split (random two-split) scenario - Various lengths ## \n",
    "\n",
    "rs_rb2 = {}\n",
    "\n",
    "for hidden_sz in [50]:\n",
    "    for block_sz in [328]:\n",
    "        rs_rb2[(hidden_sz, block_sz)] = ld.ResultSet(\n",
    "            sim_map_dict = sim_directory,\n",
    "            dataroot = project_root,\n",
    "            sim_struct = '1toM',\n",
    "            dataset_name = 'artificial_128',\n",
    "            nn_config = 'FCL50',\n",
    "            seq_type = 'random_blocks2',\n",
    "            simset_id = 328\n",
    "        )\n",
    "        rs_rb2[(hidden_sz, block_sz)].load_analytics()\n",
    "    \n",
    "## Random split (random two-split) scenario combining two frequencies - Various lengths ## \n",
    "\n",
    "# rs_rb2_2freq = {}\n",
    "\n",
    "# for hidden_sz in [10, 20, 60]:\n",
    "#     dataroot = project_root+'/Results/1toM/' + dataset + '/' + 'FCL'+str(hidden_sz) + '/' + 'random_blocks2_2freq_length200000_batches'+str(n_batches)\n",
    "#     if 'artificial' in dataset:\n",
    "#         dataroot += '_seqlen'+str(artificial_seq_len)+'_ratio'+str(linear_ratio_for_artificial_seq)\n",
    "#     for block_sz_couple in [(100, 1000), (100, 10000), (1000, 10000)]:\n",
    "#         rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = ld.ResultSet_1toM(\n",
    "#             dataroot,\n",
    "#             datapaths['1toM'][dataset]['FCL'+str(hidden_sz)]['random_blocks2_2freq'][(0.05, 8, 200000, block_sz_couple[0], block_sz_couple[1])]\n",
    "#         )\n",
    "#         rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].load_analytics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+\"/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_id, seq in enumerate(rs.train_labels_shfl[0.6][1]):\n",
    "    rs.train_labels_shfl[0.6][1][seq_id] = seq[:300001]\n",
    "\n",
    "for seq_id, seq in enumerate(rs_rb2[(50,328)].train_labels_shfl[0.0][1]):\n",
    "    rs_rb2[(50,328)].train_labels_shfl[0.0][1][seq_id] = seq[:300001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.6], shuffled_blocksz=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.6], shuffled_blocksz=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.6], shuffled_blocksz=328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.6], shuffled_blocksz=1312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.4], shuffled_blocksz=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.lbl_history([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(50, 328)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(50, 328)].lbl_history([0.0], shuffled_blocksz=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(50, 328)].lbl_history([0.0], shuffled_blocksz=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 160)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 320)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 1000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 2000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 10000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "block_sizes = [1, 82, 164, 328, 1312, 5248, 20992]\n",
    "block_sizes_commonviz = [1, 164, 328, 5248, 20992]\n",
    "\n",
    "splt_sizes_orig = {\n",
    "    0.6: (1, 82, 164, 328, 1312, 5248, 20992)\n",
    "}\n",
    "\n",
    "splt_sizes_rb = {\n",
    "    0.6: (328, (1, 82, 164, 328, 1312, 5248, 20992))\n",
    "}\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Tahoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_sizes_1 = [1, 82, 164, 328]\n",
    "\n",
    "acc_fig, acc_axes = ld.get_acc(\n",
    "    T_list = [0.6],\n",
    "    acc_temp_orig = rs.var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.6: {block_sz: rs.var_acc_shfl[0.6][block_sz] for block_sz in block_sizes_1}\n",
    "    },\n",
    "    acc_unif = [v for v in rs_unif.var_acc_orig.values()][0],\n",
    "    acc_twofold_orig = {0.6: rs_rb2[(50,328)].var_acc_orig[0.0]},\n",
    "    acc_twofold_shuffled = {\n",
    "        0.6: {block_sz: rs_rb2[(50,328)].var_acc_shfl[0.0][block_sz] for block_sz in block_sizes_1}\n",
    "    },\n",
    "    blocks_for_shared_plots = block_sizes_1,\n",
    "    seq_length = seq_length, n_tests = n_tests,\n",
    "    save_format='svg'\n",
    ")\n",
    "\n",
    "for ax in acc_axes:\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(14)\n",
    "    \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Tahoma']\n",
    "\n",
    "block_sizes_2 = [328, 1312, 5248, 20992]\n",
    "\n",
    "acc_fig, acc_axes = ld.get_acc(\n",
    "    T_list = [0.6],\n",
    "    acc_temp_orig = rs.var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.6: {block_sz: rs.var_acc_shfl[0.6][block_sz] for block_sz in block_sizes_2}\n",
    "    },\n",
    "    acc_unif = [v for v in rs_unif.var_acc_orig.values()][0],\n",
    "    acc_twofold_orig = {0.6: rs_rb2[(50,328)].var_acc_orig[0.0]},\n",
    "    acc_twofold_shuffled = {\n",
    "        0.6: {block_sz: rs_rb2[(50,328)].var_acc_shfl[0.0][block_sz] for block_sz in block_sizes_2}\n",
    "    },\n",
    "    blocks_for_shared_plots = block_sizes_2,\n",
    "    seq_length = seq_length, n_tests = n_tests,\n",
    "    save_format='svg'\n",
    ")\n",
    "\n",
    "for ax in acc_axes:\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(14)\n",
    "    \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_unif = (0, 0, 0.15)\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "markers = ['o','+','x','4','s','p','P', '8', 'h', 'X']\n",
    "var_scale = 0.5\n",
    "\n",
    "cf_randsplit = {}\n",
    "cf_randsplit_std = {}\n",
    "t_explr_randsplit = {}\n",
    "cf_ultra = {}\n",
    "cf_ultra_std = {}\n",
    "t_explr_ultra = {}\n",
    "\n",
    "avg_cf_randsplit = {}\n",
    "avg_cf_randsplit_std = {}\n",
    "avg_cf_ultra = {}\n",
    "avg_cf_ultra_std = {}\n",
    "init_cf_randsplit = {}\n",
    "init_cf_randsplit_std = {}\n",
    "init_cf_ultra = {}\n",
    "init_cf_ultra_std = {}\n",
    "\n",
    "xtick_scale = 25\n",
    "xtick_pos = xtick_scale*np.arange((n_tests//xtick_scale)+1)\n",
    "xtick_labels = int(seq_length/((n_tests//xtick_scale)))*np.arange((n_tests//xtick_scale)+1)\n",
    "\n",
    "fig_cfscore = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "\n",
    "for splt_id, (T, splt_info) in enumerate(splt_sizes_rb.items()):\n",
    "    splt_sz = splt_info[0]\n",
    "    block_sizes = splt_info[1]\n",
    "    cf_ax = plt.subplot(len(splt_sizes_rb.keys()),1,1+splt_id)\n",
    "    \n",
    "    for seq_id, seq in enumerate(rs_rb2[(hidden_sz,splt_sz)].train_labels_orig[0.0]):\n",
    "        t_explr_randsplit_orig = []\n",
    "        cf_randsplit_orig = []\n",
    "        _cf, _t_explr = ld.get_cf(seq, rs_rb2[(hidden_sz,splt_sz)].var_acc_orig[0.0][seq_id][:,0], rs_rb2[(hidden_sz,splt_sz)].var_acc_shfl[0.0][1][seq_id][:,0])\n",
    "        if _t_explr:\n",
    "            cf_aligned = np.concatenate([\n",
    "                np.array(_cf[_t_explr:]),\n",
    "                np.zeros(_t_explr)\n",
    "            ])\n",
    "            cf_randsplit_orig.append(cf_aligned)\n",
    "            t_explr_randsplit_orig.append(_t_explr)\n",
    "\n",
    "    if len(cf_randsplit_orig) > 0:\n",
    "        cf_randsplit_orig_mean = np.mean(\n",
    "            np.stack(cf_randsplit_orig, axis=1),\n",
    "            axis=1\n",
    "        )\n",
    "        cf_randsplit_orig_std = np.std(\n",
    "            np.stack(cf_randsplit_orig, axis=1),\n",
    "            axis=1\n",
    "        )\n",
    "        cf_ax.plot(\n",
    "            cf_randsplit_orig_mean,\n",
    "            color = hsv_to_rgb(hsv_tfs_orig),\n",
    "            ls = 'solid',\n",
    "            label = 'Random split sequence, split size {0:d} - No shuffling'.format(splt_sz)\n",
    "        )\n",
    "        cf_ax.fill_between(\n",
    "            x = range(len(cf_randsplit_orig_mean)),\n",
    "            y1 = cf_randsplit_orig_mean - var_scale*cf_randsplit_orig_std,\n",
    "            y2 = cf_randsplit_orig_mean + var_scale*cf_randsplit_orig_std,\n",
    "            color = hsv_to_rgb(hsv_tfs_orig),\n",
    "            alpha = 0.4\n",
    "        )\n",
    "        avg_cf_randsplit[0] = np.mean(cf_randsplit_orig_mean)\n",
    "        avg_cf_randsplit_std[0] = np.mean(cf_randsplit_orig_std)\n",
    "        init_cf_randsplit[0] = cf_randsplit_orig_mean[0]\n",
    "        init_cf_randsplit[0] = cf_randsplit_orig_std[0]\n",
    "    \n",
    "    for block_id, block_sz in enumerate(block_sizes):\n",
    "        hsv_tfs_shfl = tuple([0.35, 0.8-(block_id+1)*0.04, 0.6-(block_id+1)*0.04])\n",
    "        t_explr_randsplit[block_sz] = []\n",
    "        cf_randsplit[block_sz] = []\n",
    "        for seq_id, seq in enumerate(rs_rb2[(hidden_sz,splt_sz)].train_labels_shfl[0.0][block_sz]):\n",
    "            _cf, _t_explr = ld.get_cf(\n",
    "                seq,\n",
    "                rs_rb2[(hidden_sz,splt_sz)].var_acc_shfl[0.0][block_sz][seq_id][:,0],\n",
    "                rs_rb2[(hidden_sz,splt_sz)].var_acc_shfl[0.0][1][seq_id][:,0]\n",
    "            )\n",
    "            if _t_explr is not None:\n",
    "                cf_aligned = np.concatenate([\n",
    "                    np.array(_cf[_t_explr:]),\n",
    "                    np.zeros(_t_explr)\n",
    "                ])\n",
    "                cf_randsplit[block_sz].append(cf_aligned)\n",
    "                t_explr_randsplit[block_sz].append(_t_explr)\n",
    "\n",
    "        if len(cf_randsplit[block_sz]) > 0:\n",
    "            cf_randsplit_mean = np.mean(\n",
    "                np.stack(cf_randsplit[block_sz], axis=1),\n",
    "                axis=1\n",
    "            )\n",
    "            cf_randsplit_std = np.std(\n",
    "                np.stack(cf_randsplit[block_sz], axis=1),\n",
    "                axis=1\n",
    "            )\n",
    "            cf_ax.plot(\n",
    "                cf_randsplit_mean,\n",
    "                color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "                ls = '--',\n",
    "                label = 'Random split sequence - Shuffled w/ block size {0:d}'.format(block_sz)\n",
    "            )\n",
    "            cf_ax.fill_between(\n",
    "                x = range(len(cf_randsplit_mean)),\n",
    "                y1 = cf_randsplit_mean - var_scale*cf_randsplit_std,\n",
    "                y2 = cf_randsplit_mean + var_scale*cf_randsplit_std,\n",
    "                color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "                alpha = 0.4\n",
    "            )\n",
    "            avg_cf_randsplit[block_sz] = np.mean(cf_randsplit_mean)\n",
    "            avg_cf_randsplit_std[block_sz] = np.mean(cf_randsplit_std)\n",
    "            init_cf_randsplit[block_sz] = cf_randsplit_mean[0]\n",
    "            init_cf_randsplit_std[block_sz] = cf_randsplit_std[0]\n",
    "\n",
    "    t_explr_ultra_orig = []\n",
    "    cf_ultra_orig = []\n",
    "    for seq_id, seq in enumerate(rs.train_labels_orig[T]):\n",
    "        _cf, _t_explr = ld.get_cf(\n",
    "            seq,\n",
    "            rs.var_acc_orig[T][seq_id][:,0],\n",
    "            rs.var_acc_shfl[T][1][seq_id][:,0]\n",
    "        )\n",
    "        if _t_explr is not None:\n",
    "            cf_aligned = np.concatenate([\n",
    "                np.array(_cf[_t_explr:]),\n",
    "                np.zeros(_t_explr)\n",
    "            ])\n",
    "            cf_ultra_orig.append(cf_aligned)\n",
    "            t_explr_ultra_orig.append(_t_explr)\n",
    "        cf_ultra_orig.append(_cf)\n",
    "        t_explr_ultra_orig.append(_t_explr)\n",
    "    if len(cf_ultra_orig) > 0:\n",
    "        cf_ultra_orig_mean = np.mean(\n",
    "            np.stack(cf_ultra_orig, axis=1),\n",
    "            axis=1\n",
    "        )\n",
    "        cf_ultra_orig_std = np.std(\n",
    "            np.stack(cf_ultra_orig, axis=1),\n",
    "            axis=1\n",
    "        )\n",
    "        cf_ax.plot(\n",
    "            cf_ultra_orig_mean,\n",
    "            color = hsv_to_rgb(hsv_orig),\n",
    "            ls = 'solid',\n",
    "            label = 'Ultrametric sequence, T={0:.2f} - No shuffling'.format(T)\n",
    "        )\n",
    "        cf_ax.fill_between(\n",
    "            x = range(len(cf_ultra_orig_mean)),\n",
    "            y1 = cf_ultra_orig_mean - var_scale*cf_ultra_orig_std,\n",
    "            y2 = cf_ultra_orig_mean + var_scale*cf_ultra_orig_std,\n",
    "            color = hsv_to_rgb(hsv_orig),\n",
    "            alpha = 0.4\n",
    "        )\n",
    "        avg_cf_ultra[0] = np.mean(cf_ultra_orig_mean)\n",
    "        avg_cf_ultra_std[0] = np.mean(cf_ultra_orig_std)\n",
    "        init_cf_ultra[0] = cf_ultra_orig_mean[0]\n",
    "        init_cf_ultra_std[0] = cf_ultra_orig_std[0]\n",
    "    \n",
    "    for block_id, block_sz in enumerate(block_sizes):\n",
    "        hsv_shfl = tuple([0.6, 1-block_id*0.04, 0.4+block_id*0.03])\n",
    "        t_explr_ultra[block_sz] = []\n",
    "        cf_ultra[block_sz] = []\n",
    "        for seq_id, seq in enumerate(rs.train_labels_shfl[T][block_sz]):\n",
    "            _cf, _t_explr = ld.get_cf(\n",
    "                seq,\n",
    "                rs.var_acc_shfl[T][block_sz][seq_id][:,0],\n",
    "                rs.var_acc_shfl[T][1][seq_id][:,0]\n",
    "            )\n",
    "            if _t_explr is not None:\n",
    "                cf_aligned = np.concatenate([\n",
    "                    np.array(_cf[_t_explr:]),\n",
    "                    np.zeros(_t_explr)\n",
    "                ])\n",
    "                cf_ultra[block_sz].append(cf_aligned)\n",
    "                t_explr_ultra[block_sz].append(_t_explr)\n",
    "            cf_ultra[block_sz].append(_cf)\n",
    "            t_explr_ultra[block_sz].append(_t_explr)\n",
    "        if len(cf_ultra[block_sz]) > 0:\n",
    "            cf_ultra_mean = np.mean(\n",
    "                np.stack(cf_ultra[block_sz], axis=1),\n",
    "                axis=1\n",
    "            )\n",
    "            cf_ultra_std = np.std(\n",
    "                np.stack(cf_ultra[block_sz], axis=1),\n",
    "                axis=1\n",
    "            )\n",
    "            cf_ax.plot(\n",
    "                cf_ultra_mean,\n",
    "                color = hsv_to_rgb(hsv_shfl),\n",
    "                ls = '--',\n",
    "                label = 'Ultrametric sequence, T={0:.2f} - Shuffled w/ block size {1:d}'.format(T, block_sz)\n",
    "            )\n",
    "            cf_ax.fill_between(\n",
    "                x = range(len(cf_ultra_mean)),\n",
    "                y1 = cf_ultra_mean - var_scale*cf_ultra_std,\n",
    "                y2 = cf_ultra_mean + var_scale*cf_ultra_std,\n",
    "                color = hsv_to_rgb(hsv_shfl),\n",
    "                alpha = 0.4\n",
    "            )\n",
    "            avg_cf_ultra[block_sz] = np.mean(cf_ultra_mean)\n",
    "            avg_cf_ultra_std[block_sz] = np.mean(cf_ultra_std)\n",
    "            init_cf_ultra[block_sz] = cf_ultra_mean[0]\n",
    "            init_cf_ultra_std[block_sz] = cf_ultra_std[0]\n",
    "\n",
    "    plt.xticks(xtick_pos, xtick_labels)\n",
    "    plt.title('Per-label loss in classification performance from the moment all classes are explored', fontsize = 18)\n",
    "            \n",
    "    box = cf_ax.get_position()\n",
    "    cf_ax.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n",
    "\n",
    "    cf_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=2, prop={'size': 16})\n",
    "\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Accuracy loss from CF (%)', fontsize=14)\n",
    "\n",
    "fig_cfscore.tight_layout(pad=10.0)\n",
    "plt.savefig('out_plots_cfscore.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfmean_ultra_orig = avg_cf_ultra[0]\n",
    "cfmean_rb_orig = avg_cf_randsplit[0]\n",
    "\n",
    "xtick_pos = [k for k in sorted(avg_cf_ultra.keys()) if k>0]\n",
    "xtick_labels = [str(k) for k in sorted(avg_cf_ultra.keys()) if k>0]\n",
    "mean_cfs_ultra = [avg_cf_ultra[k] for k in sorted(avg_cf_ultra.keys()) if k>0]\n",
    "mean_cfs_rb = [avg_cf_randsplit[k] for k in sorted(avg_cf_randsplit.keys()) if k>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_origpos = 25000\n",
    "\n",
    "fig_mean_cfs = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "ax_mean_cfs = plt.subplot(111)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_ultra,\n",
    "    ls = 'solid',\n",
    "    linewidth=3,\n",
    "    marker = '+',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    label = 'Ultrametric sequence'\n",
    ")\n",
    "ax_mean_cfs.set_xticks(xtick_pos, xtick_labels)\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = xtick_pos,\n",
    "    y1 = [avg_cf_ultra[k] - var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    y2 = [avg_cf_ultra[k] + var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_ultra_orig,\n",
    "    marker = '+',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_orig)\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = [x_origpos],\n",
    "    y1 = [cfmean_ultra_orig - avg_cf_ultra_std[0]],\n",
    "    y2 = [cfmean_ultra_orig + avg_cf_ultra_std[0]],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_rb,\n",
    "    ls = '--',\n",
    "    linewidth=3,\n",
    "    marker = 'x',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    label = 'Random split sequence'\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = xtick_pos,\n",
    "    y1 = [avg_cf_randsplit[k] - var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    y2 = [avg_cf_randsplit[k] + var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_rb_orig,\n",
    "    marker = 'x',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig)\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = [x_origpos],\n",
    "    y1 = [cfmean_rb_orig - avg_cf_randsplit_std[0]],\n",
    "    y2 = [cfmean_rb_orig + avg_cf_randsplit_std[0]],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "# Plot formatting for figure 4 of paper\n",
    "\n",
    "#xtick_pos = [k for k in xtick_pos] + [x_origpos]\n",
    "#xtick_labels = [str(k) for k in xtick_pos] + [25000]\n",
    "ax_mean_cfs.set_xticks(xtick_pos)\n",
    "ax_mean_cfs.set_xticklabels(xtick_labels)\n",
    "\n",
    "plt.title('Per-label loss in classification performance as a function of shuffle block size', fontsize = 18)\n",
    "\n",
    "ax_mean_cfs.legend(fancybox=True, shadow=True, prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Average per-label loss from CF (%)', fontsize=16)\n",
    "\n",
    "fig_mean_cfs.tight_layout(pad=10.0)\n",
    "\n",
    "ax_mean_cfs.hlines(y=cfmean_ultra_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_orig))\n",
    "ax_mean_cfs.hlines(y=cfmean_rb_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_tfs_orig))\n",
    "ax_mean_cfs.vlines(x=22000, ymin=-0.1, ymax=1)\n",
    "\n",
    "#ax_mean_cfs.set_xscale(\"log\")\n",
    "\n",
    "for tick in ax_mean_cfs.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "    tick.label.set_rotation('vertical')\n",
    "    \n",
    "for tick in ax_mean_cfs.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "\n",
    "ax_mean_cfs.set_xlim(0, 1.1*x_origpos)\n",
    "ax_mean_cfs.set_ylim(-0.01, 0.2)\n",
    "\n",
    "# Saving figure\n",
    "\n",
    "plt.savefig('out_plots_cfscore_avg_linscale.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore_avg_linscale.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cf_randsplit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_origpos = 50000\n",
    "\n",
    "fig_mean_cfs = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "ax_mean_cfs = plt.subplot(111)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_ultra,\n",
    "    ls = 'solid',\n",
    "    linewidth=3,\n",
    "    marker = '+',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    label = 'Ultrametric sequence'\n",
    ")\n",
    "ax_mean_cfs.set_xticks(xtick_pos, xtick_labels)\n",
    "#ax_mean_cfs.fill_between(\n",
    "#    x = xtick_pos,\n",
    "#    y1 = [avg_cf_ultra[k] - var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "#    y2 = [avg_cf_ultra[k] + var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "#    color = hsv_to_rgb(hsv_orig),\n",
    "#    alpha = 0.2\n",
    "#)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_ultra_orig,\n",
    "    marker = '+',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_orig)\n",
    ")\n",
    "#ax_mean_cfs.fill_between(\n",
    "#    x = [x_origpos],\n",
    "#    y1 = [cfmean_ultra_orig - avg_cf_ultra_std[0]],\n",
    "#    y2 = [cfmean_ultra_orig + avg_cf_ultra_std[0]],\n",
    "#    color = hsv_to_rgb(hsv_orig),\n",
    "#    alpha = 0.2\n",
    "#)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_rb,\n",
    "    ls = '--',\n",
    "    linewidth=3,\n",
    "    marker = 'x',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    label = 'Random split sequence'\n",
    ")\n",
    "#ax_mean_cfs.fill_between(\n",
    "#    x = xtick_pos,\n",
    "#    y1 = [avg_cf_randsplit[k] - var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "#    y2 = [avg_cf_randsplit[k] + var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "#    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "#    alpha = 0.2\n",
    "#)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_rb_orig,\n",
    "    marker = 'x',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig)\n",
    ")\n",
    "#ax_mean_cfs.fill_between(\n",
    "#    x = [x_origpos],\n",
    "#    y1 = [cfmean_rb_orig - avg_cf_randsplit_std[0]],\n",
    "#    y2 = [cfmean_rb_orig + avg_cf_randsplit_std[0]],\n",
    "#    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "#    alpha = 0.2\n",
    "#)\n",
    "\n",
    "# Plot formatting for figure 4 of paper\n",
    "\n",
    "#xtick_pos = [k for k in xtick_pos] + [x_origpos]\n",
    "#xtick_labels = [str(k) for k in xtick_pos] + [25000]\n",
    "ax_mean_cfs.set_xticks(xtick_pos)\n",
    "ax_mean_cfs.set_xticklabels(xtick_labels)\n",
    "\n",
    "plt.title('Per-label loss in classification performance as a function of shuffle block size', fontsize = 18)\n",
    "\n",
    "ax_mean_cfs.legend(fancybox=True, shadow=True, prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Average per-label loss from CF (%)', fontsize=16)\n",
    "\n",
    "fig_mean_cfs.tight_layout(pad=10.0)\n",
    "\n",
    "ax_mean_cfs.hlines(y=cfmean_ultra_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_orig))\n",
    "ax_mean_cfs.hlines(y=cfmean_rb_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_tfs_orig))\n",
    "ax_mean_cfs.vlines(x=30000, ymin=-0.1, ymax=1)\n",
    "\n",
    "ax_mean_cfs.set_xscale(\"log\")\n",
    "\n",
    "for tick in ax_mean_cfs.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "    tick.label.set_rotation('vertical')\n",
    "    \n",
    "for tick in ax_mean_cfs.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "\n",
    "ax_mean_cfs.set_xlim(0, 1.1*x_origpos)\n",
    "ax_mean_cfs.set_ylim(-0.01, 0.2)\n",
    "\n",
    "# Saving figure\n",
    "\n",
    "plt.savefig('out_plots_cfscore_avg_logscale.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore_avg_logscale.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in sorted(avg_cf_ultra.keys()) if k>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "cf_blsz_ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(\n",
    "    [k for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    [init_cf_ultra[k] for k in sorted(init_cf_ultra.keys()) if k!=1],\n",
    "    ls = 'solid',\n",
    "    linewidth=3,\n",
    "    marker = '+',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    label = 'Ultrametric sequence'\n",
    ")\n",
    "cf_blsz_ax.fill_between(\n",
    "    x = [k for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    y1 = [init_cf_ultra[k] - var_scale*init_cf_ultra_std[k] for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    y2 = [init_cf_ultra[k] + var_scale*init_cf_ultra_std[k] for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [k for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    [init_cf_randsplit[k] for k in sorted(init_cf_randsplit.keys()) if k!=1],\n",
    "    ls = '--',\n",
    "    linewidth=3,\n",
    "    marker = 'x',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    label = 'Random split sequence'\n",
    ")\n",
    "cf_blsz_ax.fill_between(\n",
    "    x = [k for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    y1 = [init_cf_randsplit[k] - var_scale*init_cf_randsplit_std[k] for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    y2 = [init_cf_randsplit[k] + var_scale*init_cf_randsplit_std[k] for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "plt.title('Per-label loss in classification performance as a function of shuffle block size', fontsize = 18)\n",
    "\n",
    "cf_blsz_ax.legend(fancybox=True, shadow=True, prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Average per-label loss from CF (%)', fontsize=16)\n",
    "\n",
    "fig.tight_layout(pad=10.0)\n",
    "plt.savefig('out_plots_cfscore_init.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore_init.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_cf(\n",
    "    rs_rb2[(hidden_sz,block_sz)].train_labels_orig[0.0][0],\n",
    "    rs_rb2[(hidden_sz,block_sz)].var_acc_orig[0.0][0][:,0],\n",
    "    rs_rb2[(hidden_sz,block_sz)].var_acc_shfl[0.0][1][0][:,0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(hidden_sz,block_sz)].var_acc_shfl[0.0][1][0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.5],\n",
    "    acc_temp_orig = rs.var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.5: {block_sz: rs.var_acc_shfl[0.5][block_sz] for block_sz in [1, 20, 32, 80, 160, 320, 1600]}\n",
    "    },\n",
    "    acc_unif = [v for v in rs_unif.var_acc_orig.values()][0],\n",
    "    acc_twofold_orig = {0.5: rs_rb2[(20, 160)].var_acc_orig[0.0]},\n",
    "    acc_twofold_shuffled = {\n",
    "        0.5: {block_sz: rs_rb2[(20, 160)].var_acc_shfl[0.0][block_sz] for block_sz in [1, 20, 32, 80, 160, 320, 1600]}\n",
    "    },\n",
    "    blocks_for_shared_plots = [1, 32, 80, 160],\n",
    "    var_scale = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb.runcall(ld.get_acc,\n",
    "            T_list = [0.5],\n",
    "            acc_temp_orig = rs.var_acc_orig,\n",
    "            acc_temp_shuffled = {\n",
    "                0.5: {block_sz: rs.var_acc_shfl[0.5][block_sz] for block_sz in [1, 20, 64, 160, 1600, 8000]}\n",
    "            },\n",
    "            acc_unif = [v for v in rs_unif.var_acc_orig.values()][0],\n",
    "            acc_twofold_orig = {0.5: rs_rb2[(20, 320)].var_acc_orig[0.0]},\n",
    "            acc_twofold_shuffled = {\n",
    "                0.5: {block_sz: rs_rb2[(20, 320)].var_acc_shfl[0.0][block_sz] for block_sz in [1, 20, 64, 160, 1600, 8000]}\n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20,1000)].var_acc_orig[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[100].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[100].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[1000].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[1000].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[10000].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[10000].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unit = {}\n",
    "cf = {}\n",
    "cf_explr = {}\n",
    "\n",
    "for hidden_sz in [5, 10, 20, 60, 200]:\n",
    "    for block_sz in [10, 100, 1000, 4000, 8000, 10000]:\n",
    "        cf_unit[(hidden_sz,block_sz)] = []\n",
    "        n_seq = len(rs_rb2[(hidden_sz, block_sz)].var_acc_orig[0.0])\n",
    "        cf_at_fullexplr = []\n",
    "        for seq_id in range(n_seq):\n",
    "            _cf, _t_explr = ld.get_cf(\n",
    "                    rs_rb2[(hidden_sz,block_sz)].train_labels_orig[0.0][seq_id],\n",
    "                    rs_rb2[(hidden_sz,block_sz)].var_acc_orig[0.0][seq_id][:,0],\n",
    "                    rs_rb2[(hidden_sz,block_sz)].var_acc_shfl[0.0][1][0][:,0]\n",
    "                )\n",
    "            cf_unit[(hidden_sz,block_sz)].append(_cf)\n",
    "            cf_at_fullexplr.append(_cf[_t_explr])\n",
    "        cf_unit[(hidden_sz,block_sz)] = np.stack(cf_unit[(hidden_sz,block_sz)], axis=1)\n",
    "        cf[(hidden_sz,block_sz)] = np.mean(cf_unit[(hidden_sz,block_sz)], axis=1)\n",
    "        cf_explr[(hidden_sz,block_sz)] = np.mean(np.array(cf_at_fullexplr))\n",
    "    \n",
    "    if hidden_sz in [10, 20, 60]:\n",
    "        for block_sz_couple in [(100, 1000), (100, 10000), (1000, 10000)]:\n",
    "            cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = []\n",
    "            n_seq = len(rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_orig[0.0])\n",
    "            for seq_id in range(n_seq):\n",
    "                cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].append(\n",
    "                    ld.get_cf(\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].train_labels_orig[0.0][seq_id],\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_orig[0.0][seq_id][:,0],\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_shfl[0.0][1][0][:,0]\n",
    "                    )\n",
    "                )\n",
    "            cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = np.stack(cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])], axis=1)\n",
    "            cf[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = np.mean(cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "cf_ax = plt.subplot(111)\n",
    "for block_sz in [10, 100, 1000, 10000]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz)],\n",
    "        label='Forgetting score - Split size {0:d}'.format(block_sz)\n",
    "    )\n",
    "cf_ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.15),\n",
    "\t\t\t\t\t  fancybox=True, shadow=True, ncol=2,\n",
    "\t\t\t\t\t  prop={'size': 16})\n",
    "plt.title(\"Catastrophic forgetting on split sequences as a function of split sequence length\", fontsize = 14)\n",
    "plt.xlabel('CF score', fontsize=14)\n",
    "plt.ylabel('Iterations', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "cf_ax = plt.subplot(111)\n",
    "\n",
    "for block_sz in [1000, 10000]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz)],\n",
    "        label='Forgetting score - Split size {0:d}'.format(block_sz)\n",
    "    )\n",
    "\n",
    "for block_sz_couple in [(1000, 10000)]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz_couple[0], block_sz_couple[1])],\n",
    "        label='Forgetting score - Split size {0:d} x {1:d}'.format(block_sz_couple[0], block_sz_couple[1])\n",
    "    )\n",
    "\n",
    "cf_ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.15),\n",
    "\t\t\t\t\t  fancybox=True, shadow=True, ncol=2,\n",
    "\t\t\t\t\t  prop={'size': 16})\n",
    "plt.title(\"Catastrophic forgetting on split sequences as a function of split sequence length\", fontsize = 14)\n",
    "plt.ylabel('CF score', fontsize=14)\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "\n",
    "n_tests=200\n",
    "seq_length=200000\n",
    "xtick_scale = 25\n",
    "xtick_pos = xtick_scale*np.arange((n_tests//xtick_scale)+1)\n",
    "xtick_labels = int(seq_length/((n_tests//xtick_scale)))*np.arange((n_tests//xtick_scale)+1)\n",
    "plt.xticks(xtick_pos, xtick_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's try to obtain a plot of mean CF score as a function of (hidden_sz, block_sz) for single-frequency signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "cf_ax = plt.axes(projection='3d')\n",
    "\n",
    "hidden_sizes = [5, 10, 20, 60, 200]\n",
    "block_sizes = [10, 100, 1000, 4000, 8000, 10000]\n",
    "\n",
    "cf_avg = {}\n",
    "\n",
    "for hidden_sz in hidden_sizes:\n",
    "    for block_sz in block_sizes:\n",
    "        # cf_avg[(hidden_sz, block_sz)] = np.mean(cf[(hidden_sz, block_sz)])\n",
    "        cf_avg[(hidden_sz, block_sz)] = cf_explr[(hidden_sz,block_sz)]\n",
    "    \n",
    "    cf_avg_arr = np.array([cf_avg[(hidden_sz, bs)] for bs in block_sizes])\n",
    "    cf_ax.plot(\n",
    "        hidden_sz*np.ones(len(block_sizes)),\n",
    "        #np.log10(np.array(block_sizes)),\n",
    "        np.array(block_sizes),\n",
    "        cf_avg_arr\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a posteriori)\n",
    "\n",
    "Let's plot the autocorrelation function to DARPA standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.get_atc(\n",
    "    T_list=[0.4],\n",
    "    n_tests=10,\n",
    "    out_filename='atc_artificial32_T04'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a posteriori)\n",
    "\n",
    "Let's plot the autocorrelation function to DARPA standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_sizes = [1, 10, 100, 1000]\n",
    "n_tests = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from tqdm.notebook import tqdm\n",
    "from numba import jit\n",
    "from typing import List\n",
    "\n",
    "def shuffleblocks(seq, block_sz, snbr):\n",
    "    lseq = len(seq)\n",
    "    copied_seq = list(seq)\n",
    "    sseq = []   # Will contain the shuffled sequence\n",
    "    for k in range(snbr):\n",
    "        begin, end = int(k*lseq/snbr), int((k+1)*lseq/snbr)\n",
    "        bbegin, bend = int(begin/block_sz), int(end/block_sz)\n",
    "        block_indices = [i for i in range(len(seq[:end])//block_sz)]\n",
    "        random.shuffle(block_indices)\n",
    "        for i in block_indices[bbegin:bend]:\n",
    "            sseq += copied_seq[i*block_sz:(i+1)*block_sz]\n",
    "    return sseq\n",
    "\n",
    "@jit(nopython=True)\n",
    "def get_atc_forloop(seq_list, blocks, snbr, filename, T, w_size=10000):\n",
    "    tree_l = max(seq_list[0])+1\n",
    "\n",
    "    hlocs_stat_orig = np.zeros(w_size)\n",
    "    hlocs_stat_shfl = np.zeros(w_size)\n",
    "    \n",
    "    bins_hist = range(w_size)\n",
    "    \n",
    "    def shuffleblocks(seq, block_sz, snbr):\n",
    "        lseq = len(seq)\n",
    "        copied_seq = list(seq)\n",
    "        sseq = [0]   # Will contain the shuffled sequence\n",
    "        for k in range(snbr):\n",
    "            begin, end = int(k*lseq/snbr), int((k+1)*lseq/snbr)\n",
    "            bbegin, bend = int(begin/block_sz), int(end/block_sz)\n",
    "            block_indices = [i for i in range(len(seq[:end])//block_sz)]\n",
    "            perm = np.random.permutation(len(block_indices))\n",
    "            perm_indices = [block_indices[k] for k in perm]\n",
    "            for i in perm_indices[bbegin:bend]:\n",
    "                sseq += copied_seq[i*block_sz:(i+1)*block_sz]\n",
    "        sseq.pop(0)\n",
    "        return sseq \n",
    "    \n",
    "    for seq_id in range(len(seq_list)):\n",
    "        seq = seq_list[seq_id]\n",
    "        for lbl_id in range(tree_l):\n",
    "            locs_orig = np.array([j for j in range(len(seq)) if seq[j]==lbl_id])\n",
    "            nlocs = len(locs_orig)\n",
    "            \n",
    "            for loc1_id in range(nlocs):\n",
    "                if loc1_id == nlocs-1:\n",
    "                    break\n",
    "                for loc2_id in range(1+loc1_id, nlocs):\n",
    "                    locd = locs_orig[loc2_id] - locs_orig[loc1_id]\n",
    "                    if locd > w_size:\n",
    "                        break\n",
    "                    hlocs_stat_orig[locd] += 1\n",
    "\n",
    "    if hlocs_stat_orig[0] > 0:\n",
    "        hlocs_stat_orig = hlocs_stat_orig / hlocs_stat_orig[0]\n",
    "        \n",
    "    bins_atc = range(w_size//2)\n",
    "    # plt.loglog(\n",
    "    #     bins_atc,\n",
    "    #     hlocs_stat_orig[::2],\n",
    "    #     marker='.',\n",
    "    #     color = hsv_to_rgb(hsv_orig),\n",
    "    #     ls = 'solid',\n",
    "    #     label='T={0:.2f} - Original sequence'.format(T)\n",
    "    # ) \n",
    "    \n",
    "    hlocs_stat_shfl_list = []\n",
    "    for block_sz_id in range(len(blocks)):\n",
    "        block_sz = blocks[block_sz_id]\n",
    "        #plt.figure(nfig+2)\n",
    "        #plt.plot(shuffleseq)\n",
    "        #plt.title(block_sz)\n",
    "        for seq_id in range(len(seq_list)):\n",
    "            seq = seq_list[seq_id]\n",
    "            shuffleseq = shuffleblocks(seq, block_sz, snbr)\n",
    "            for lbl_id in range(tree_l):\n",
    "                locs_shfl_flat = np.array([j for j in range(len(seq)) if seq[j]==lbl_id])\n",
    "                nlocs = len(locs_shfl_flat)\n",
    "                locs_shfl = locs_shfl_flat.reshape((nlocs, 1))\n",
    "\n",
    "                for loc1_id in range(nlocs):\n",
    "                    if loc1_id == nlocs-1:\n",
    "                        break\n",
    "                    for loc2_id in range(1+loc1_id, nlocs):\n",
    "                        locd = locs_orig[loc2_id] - locs_orig[loc1_id]\n",
    "                        if locd > w_size:\n",
    "                            break\n",
    "                        hlocs_stat_shfl[locd] += 1\n",
    "        \n",
    "        if hlocs_stat_shfl[0] > 0:\n",
    "            hlocs_stat_shfl = hlocs_stat_shfl / hlocs_stat_shfl[0]\n",
    "        \n",
    "        # plt.figure(1)    \n",
    "        # plt.loglog(\n",
    "        #     bins_atc,\n",
    "        #     hlocs_stat_shfl[::2],\n",
    "        #     marker = markers[nfig],\n",
    "        #     ls = 'solid',\n",
    "        #     color = hsv_to_rgb(hsv_shfl),\n",
    "        #     label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(T, block_sz),\n",
    "        #     alpha=0.5) \n",
    "        hlocs_stat_shfl_list.append(hlocs_stat_shfl)\n",
    "        \n",
    "    # plt.title('Autocorrelation of training sequence')\n",
    "    # plt.xlabel('t, number of iterations /2', fontsize=12)\n",
    "    # plt.ylabel('A(t)', fontsize=14)\n",
    "    # plt.legend(prop={'size': 16})\n",
    "    \n",
    "    # plt.savefig(\n",
    "    #     fname=filename+'.pdf',\n",
    "    #     format='pdf'\n",
    "    # )\n",
    "        \n",
    "    return hlocs_stat_orig, hlocs_stat_shfl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlocs_stat_orig, hlocs_stat_shfl_list = get_atc_forloop(\n",
    "    rs.train_labels_orig[0.4],\n",
    "    blocks=[1, 100, 200, 400, 800, 1600, 8000],\n",
    "    snbr=10,\n",
    "    filename='atc_artificial32_T04',\n",
    "    T=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atc_vectorized(seq_list, blocks, snbr, filename, T, w_size=10000):\n",
    "    tree_l = max(seq_list[0])+1\n",
    "    plt.figure(1, figsize=(18,10))\n",
    "    hlocs_stat_orig = np.zeros(w_size)\n",
    "    hlocs_stat_shfl = np.zeros(w_size)\n",
    "    \n",
    "    hsv_orig = (0, 0.9, 0.6)\n",
    "    n_omits = 30\n",
    "    markers = ['o','+','x',',']\n",
    "    bins_hist = range(w_size)\n",
    "    \n",
    "    print(\"Computing autocorrelation on {0:d} sequences\".format(len(seq_list)))\n",
    "    \n",
    "    for seq_id, seq in tqdm(enumerate(seq_list), desc='Sequence #'):\n",
    "        print(\"   Original sequence {0:d}...\".format(seq_id))\n",
    "        for lbl_id in tqdm(range(tree_l), desc='Leaf #'):\n",
    "            locs_orig = np.array([j for j in range(len(seq)) if seq[j]==lbl_id])\n",
    "            nlocs = len(locs_orig)\n",
    "            locs_orig = locs_orig.reshape((nlocs, 1))\n",
    "            \n",
    "            locsd_mat_orig = cdist(locs_orig, locs_orig, 'cityblock')\n",
    "            #     iu_ids_couples = np.array([(i,j) for j in range(20) for i in range(20*cut_id, 20*cut_id+j)])\n",
    "            iu_ids = np.triu_indices(nlocs)\n",
    "            iu_len = len(iu_ids[0])\n",
    "            diffs = locsd_mat_orig[iu_ids].reshape((iu_len,1))\n",
    "            hlocs_orig = hlocs_orig + np.histogram(\n",
    "                diffs,\n",
    "                bins=w_size,\n",
    "                range=(0,w_size)\n",
    "            )\n",
    "            hlocs_stat_orig = hlocs_stat_orig + hlocs_orig[0]/tree_l\n",
    "\n",
    "        print(\"   ...done\")\n",
    "\n",
    "\n",
    "    if hlocs_stat_orig[0] > 0:\n",
    "        hlocs_stat_orig = hlocs_stat_orig / hlocs_stat_orig[1]\n",
    "        \n",
    "    bins_atc = range(w_size//2)\n",
    "    plt.loglog(\n",
    "        bins_atc,\n",
    "        hlocs_stat_orig[::2],\n",
    "        marker='.',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        ls = 'solid',\n",
    "        label='T={0:.2f} - Original sequence'.format(T)\n",
    "    ) \n",
    "    \n",
    "    hlocs_stat_shfl_list = []\n",
    "    for nfig, block_sz in enumerate(blocks):\n",
    "        print(\"   Block size {0:d}\".format(block_sz))\n",
    "        hsv_shfl = tuple([0.6, 1-nfig*0.2, 0.5+nfig*0.15])\n",
    "        #plt.figure(nfig+2)\n",
    "        #plt.plot(shuffleseq)\n",
    "        #plt.title(block_sz)\n",
    "        for seq_id, seq in enumerate(seq_list):\n",
    "            shuffleseq = shuffleblocks(seq, block_sz, snbr)\n",
    "            print(\"       Shuffled sequence {1:d}...\".format(block_sz, seq_id))\n",
    "            for lbl_id in range(tree_l):\n",
    "                locs_shfl = np.array([j for j in range(len(shuffleseq)) if  shuffleseq[j]==lbl_id])\n",
    "                nlocs = len(locs_shfl)\n",
    "                locs_shfl = locs_shfl.reshape((nlocs, 1))\n",
    "                locsd_mat_shfl = cdist(locs_shfl, locs_shfl, 'cityblock')     \n",
    "                iu_ids = np.triu_indices(nlocs)\n",
    "                bins = range(w_size)\n",
    "                hlocs_shfl = np.bincount(\n",
    "                    locsd_mat_shfl[iu_ids].reshape((int(nlocs*(nlocs+1)/2),1))\n",
    "                )\n",
    "                # hlocs_shfl = np.histogram(\n",
    "                #     locsd_mat_shfl[iu_ids].reshape((int(nlocs*(nlocs+1)/2),1)),\n",
    "                #     bins=w_size,\n",
    "                #     range=(0, w_size)\n",
    "                # )\n",
    "                \n",
    "                hlocs_stat_shfl = hlocs_stat_shfl + hlocs_shfl[0]/tree_l\n",
    "            print(\"       ...done\")\n",
    "        \n",
    "        if hlocs_stat_shfl[0] > 0:\n",
    "            hlocs_stat_shfl = hlocs_stat_shfl / hlocs_stat_shfl[0]\n",
    "        \n",
    "        plt.figure(1)    \n",
    "        plt.loglog(\n",
    "            bins_atc,\n",
    "            hlocs_stat_shfl[::2],\n",
    "            marker = markers[nfig],\n",
    "            ls = 'solid',\n",
    "            color = hsv_to_rgb(hsv_shfl),\n",
    "            label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(T, block_sz),\n",
    "            alpha=0.5) \n",
    "        hlocs_stat_shfl_list.append(hlocs_stat_shfl)\n",
    "        \n",
    "    plt.title('Autocorrelation of training sequence')\n",
    "    plt.xlabel('t, number of iterations /2', fontsize=12)\n",
    "    plt.ylabel('A(t)', fontsize=14)\n",
    "    plt.legend(prop={'size': 16})\n",
    "    \n",
    "    plt.savefig(\n",
    "        fname=filename+'.pdf',\n",
    "        format='pdf'\n",
    "    )\n",
    "        \n",
    "    return hlocs_stat_orig, hlocs_stat_shfl_list\n",
    "\n",
    "\n",
    "\n",
    "def get_atc_matrixcuts(seq_list, blocks, snbr, filename, T, w_size=10000):\n",
    "    tree_l = max(seq_list[0])+1\n",
    "    plt.figure(1, figsize=(18,10))\n",
    "    hlocs_orig = np.zeros((w_size,1))\n",
    "    hlocs_shfl = np.zeros((w_size,1))\n",
    "    \n",
    "    hsv_orig = (0, 0.9, 0.6)\n",
    "    n_omits = 30\n",
    "    markers = ['o','+','x',',']\n",
    "    bins_hist = range(w_size)\n",
    "    \n",
    "    print(\"Computing autocorrelation on {0:d} sequences\".format(len(seq_list)))\n",
    "    \n",
    "    for seq_id, seq in tqdm(enumerate(seq_list), desc='Sequence #'):\n",
    "        print(\"   Original sequence {0:d}...\".format(seq_id))\n",
    "        for lbl_id in tqdm(range(tree_l), desc='Leaf #'):\n",
    "            locs_orig = np.array([j for j in range(len(seq)) if seq[j]==lbl_id])\n",
    "            nlocs = len(locs_orig)\n",
    "            locs_orig = locs_orig.reshape((nlocs, 1))\n",
    "            \n",
    "            for cut_id in tqdm(range(nlocs//20 - 1), desc='Split', leave=False):\n",
    "                locs = locs_orig[cut_id*20:(cut_id+1)*20,:]\n",
    "                locsd_mat_orig = cdist(locs_orig, locs, 'cityblock')\n",
    "                iu_ids_couples = np.array([(i,j) for j in range(20) for i in range(20*cut_id, 20*cut_id+j)])\n",
    "                iu_ids = (iu_ids_couples[:,0], iu_ids_couples[:,1])\n",
    "                iu_len = len(iu_ids[0])\n",
    "                diffs = locsd_mat_orig[iu_ids].reshape((iu_len,1))\n",
    "                hlocs_orig = hlocs_orig + np.histogram(\n",
    "                    diffs,\n",
    "                    bins=w_size,\n",
    "                    range=(0,w_size)\n",
    "                )\n",
    "\n",
    "        print(\"   ...done\")\n",
    "\n",
    "    hlocs_stat_orig = hlocs_orig.tolist()\n",
    "    if hlocs_stat_orig[1] > 0:\n",
    "        hlocs_stat_orig = hlocs_stat_orig / hlocs_stat_orig[1]\n",
    "        \n",
    "    bins_atc = range(w_size//2)\n",
    "    plt.loglog(\n",
    "        bins_atc,\n",
    "        hlocs_stat_orig[::2],\n",
    "        marker='.',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        ls = 'solid',\n",
    "        label='T={0:.2f} - Original sequence'.format(T)\n",
    "    ) \n",
    "    \n",
    "    hlocs_stat_shfl_list = []\n",
    "    for nfig, block_sz in enumerate(blocks):\n",
    "        print(\"   Block size {0:d}\".format(block_sz))\n",
    "        hsv_shfl = tuple([0.6, 1-nfig*0.2, 0.5+nfig*0.15])\n",
    "        #plt.figure(nfig+2)\n",
    "        #plt.plot(shuffleseq)\n",
    "        #plt.title(block_sz)\n",
    "        for seq_id, seq in enumerate(seq_list):\n",
    "            shuffleseq = shuffleblocks(seq, block_sz, snbr)\n",
    "            print(\"       Shuffled sequence {1:d}...\".format(block_sz, seq_id))\n",
    "            for lbl_id in range(tree_l):\n",
    "                locs_shfl = np.array([j for j in range(len(shuffleseq)) if  shuffleseq[j]==lbl_id])\n",
    "                nlocs = len(locs_shfl)\n",
    "                locs_shfl = locs_shfl.reshape((nlocs, 1))\n",
    "                locsd_mat_shfl = cdist(locs_shfl, locs_shfl, 'cityblock')     \n",
    "                iu_ids = np.triu_indices(nlocs)\n",
    "                bins = range(w_size)\n",
    "                hlocs_shfl = np.bincount(\n",
    "                    locsd_mat_shfl[iu_ids].reshape((int(nlocs*(nlocs+1)/2),1))\n",
    "                )\n",
    "                # hlocs_shfl = np.histogram(\n",
    "                #     locsd_mat_shfl[iu_ids].reshape((int(nlocs*(nlocs+1)/2),1)),\n",
    "                #     bins=w_size,\n",
    "                #     range=(0, w_size)\n",
    "                # )\n",
    "                \n",
    "                hlocs_stat_shfl = hlocs_stat_shfl + hlocs_shfl[0]/tree_l\n",
    "            print(\"       ...done\")\n",
    "        \n",
    "        if hlocs_stat_shfl[0] > 0:\n",
    "            hlocs_stat_shfl = hlocs_stat_shfl / hlocs_stat_shfl[0]\n",
    "        \n",
    "        plt.figure(1)    \n",
    "        plt.loglog(\n",
    "            bins_atc,\n",
    "            hlocs_stat_shfl[::2],\n",
    "            marker = markers[nfig],\n",
    "            ls = 'solid',\n",
    "            color = hsv_to_rgb(hsv_shfl),\n",
    "            label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(T, block_sz),\n",
    "            alpha=0.5)\n",
    "        hlocs_stat_shfl_list.append(hlocs_stat_shfl)\n",
    "        \n",
    "    plt.title('Autocorrelation of training sequence')\n",
    "    plt.xlabel('t, number of iterations /2', fontsize=12)\n",
    "    plt.ylabel('A(t)', fontsize=14)\n",
    "    plt.legend(prop={'size': 16})\n",
    "    \n",
    "    plt.savefig(\n",
    "        fname=filename+'.pdf',\n",
    "        format='pdf'\n",
    "    )\n",
    "        \n",
    "    return hlocs_stat_orig, hlocs_stat_shfl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "os.chdir(project_root+'/plots/artificial_32')\n",
    "\n",
    "plt.figure(1, figsize=(18,10))\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x',',']\n",
    "block_sizes = (1, 10, 100, 1000)\n",
    "\n",
    "bins_atc = range(w_size//2)\n",
    "tmp_orig = copy.deepcopy(hlocs_stat_orig)\n",
    "tmp_orig[1::2] = None\n",
    "\n",
    "plt.loglog(\n",
    "    bins_atc,\n",
    "    hlocs_stat_orig[::2],\n",
    "    marker='.',\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    ls = 'solid',\n",
    "    label='T={0:.2f} - Original sequence'.format(0.4)\n",
    ")\n",
    "\n",
    "for nfig, hlocs_stat_shfl in enumerate(hlocs_stat_shfl_list):\n",
    "    hsv_shfl = tuple([0.6, 1-nfig*0.2, 0.5+nfig*0.15])\n",
    "    block_sz = block_sizes[nfig]\n",
    "    tmp_shfl = copy.deepcopy(hlocs_stat_shfl)\n",
    "    tmp_shfl[1::2] = None\n",
    "    plt.loglog(\n",
    "        bins_atc,\n",
    "        hlocs_stat_shfl[::2],\n",
    "        marker = markers[nfig],\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(0.4, block_sz),\n",
    "        alpha=0.5)\n",
    "    \n",
    "plt.legend(prop={'size': 16})\n",
    "plt.title('Autocorrelation of training sequence', fontsize=16)\n",
    "plt.xlabel('t, number of iterations /2', fontsize=14)\n",
    "plt.ylabel('A(t)', fontsize=14)\n",
    "\n",
    "plt.savefig(\n",
    "    fname='atc_artificial32_T04',\n",
    "    format='pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+'/plots/artificial_32')\n",
    "\n",
    "plt.figure(1, figsize=(18,10))\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x',',']\n",
    "block_sizes = (1, 10, 100, 1000)\n",
    "\n",
    "bins_atc = range(w_size//2)\n",
    "tmp_orig = copy.deepcopy(hlocs_stat_orig)\n",
    "tmp_orig[1::2] = None\n",
    "\n",
    "plt.loglog(\n",
    "    bins_atc,\n",
    "    hlocs_stat_orig[::2],\n",
    "    marker='.',\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    ls = 'solid',\n",
    "    label='T={0:.2f} - Original sequence'.format(0.4)\n",
    ")\n",
    "\n",
    "for nfig, hlocs_stat_shfl in enumerate(hlocs_stat_shfl_list):\n",
    "    hsv_shfl = tuple([0.6, 1-nfig*0.2, 0.5+nfig*0.15])\n",
    "    block_sz = block_sizes[nfig]\n",
    "    tmp_shfl = copy.deepcopy(hlocs_stat_shfl)\n",
    "    tmp_shfl[1::2] = None\n",
    "    plt.loglog(\n",
    "        bins_atc,\n",
    "        hlocs_stat_shfl[::2],\n",
    "        marker = markers[nfig],\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f} - Shuffled with blocksz={1:d}'.format(0.4, block_sz),\n",
    "        alpha=0.5)\n",
    "    \n",
    "plt.legend(prop={'size': 16})\n",
    "plt.title('Autocorrelation of training sequence', fontsize=16)\n",
    "plt.xlabel('t, number of iterations /2', fontsize=14)\n",
    "plt.ylabel('A(t)', fontsize=14)\n",
    "\n",
    "plt.savefig(\n",
    "    fname='atc_artificial32_T04',\n",
    "    format='pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlocs_stat_orig_065, hlocs_stat_shfl_list_065 = get_atc(\n",
    "    rs.train_labels_orig[(0.65, 10)],\n",
    "    block_sizes,\n",
    "    n_tests,\n",
    "    'atc_artificial32_T065'\n",
    "    T=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "acc_fig = plt.figure(figsize=(20,3*11))\n",
    "n_tests = int(rs.params[(0.4, 1)][0]['Number of tests'])\n",
    "xtick_scale = 25\n",
    "xtick_pos = xtick_scale*np.arange((n_tests//xtick_scale)+1)\n",
    "xtick_labels = int(seq_length/((n_tests//xtick_scale)))*np.arange((n_tests//xtick_scale)+1)\n",
    "\n",
    "hsv_unif = (0, 0, 0.15)\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x','4','s','p','P']\n",
    "\n",
    "acc_ax = plt.subplot(311)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs200k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs200k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs200k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs200k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "\n",
    "acc_ax = plt.subplot(312)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs40k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs40k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs40k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs40k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "\n",
    "acc_ax = plt.subplot(313)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs20k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs20k.var_acc_orig.items() for acc in accs if params[0]==0.40], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.40)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.4, 1), (0.4, 1000), (0.4, 5000), (0.4, 20000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs20k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs20k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences', fontsize = 14)\n",
    "\n",
    "box = acc_ax.get_position()\n",
    "acc_ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "acc_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "              fancybox=True, shadow=True, ncol=2,\n",
    "              prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "plt.savefig('out_plots_acc.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "acc_fig = plt.figure(figsize=(20,3*11))\n",
    "n_tests = int(rs.params[(0.4, 1)][0]['Number of tests'])\n",
    "xtick_scale = 25\n",
    "xtick_pos = xtick_scale*np.arange((n_tests//xtick_scale)+1)\n",
    "xtick_labels = int(seq_length/((n_tests//xtick_scale)))*np.arange((n_tests//xtick_scale)+1)\n",
    "\n",
    "hsv_unif = (0, 0, 0.15)\n",
    "hsv_orig = (0, 0.9, 0.6)\n",
    "markers = ['o','+','x','4','s','p','P']\n",
    "\n",
    "acc_ax = plt.subplot(311)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 10), (0.5, 1000), (0.5, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs200k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs200k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 100), (0.5, 1000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs200k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs200k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "\n",
    "acc_ax = plt.subplot(312)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 10), (0.5,100), (0.5, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs40k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs40k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 100), (0.5, 1000), (0.5, 5000), (0.5, 20000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs40k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs40k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "\n",
    "acc_ax = plt.subplot(313)\n",
    "\n",
    "## Plotting average performance for random sequences (from uniform distr)\n",
    "\n",
    "var_acc_unif = np.mean([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_unif_std = np.std([acc[:,0] for params, accs in rs_unif.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_unif,\n",
    "        ls = 'solid',\n",
    "        color = hsv_to_rgb(hsv_unif),\n",
    "        label='T={0:.2f} - Uniform learning'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_unif)),\n",
    "    y1 = var_acc_unif - var_acc_unif_std,\n",
    "    y2 = var_acc_unif + var_acc_unif_std,\n",
    "    color = hsv_to_rgb(hsv_unif),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "\n",
    "## Plotting average performance for original ultrametric sequences\n",
    "\n",
    "var_acc_orig = np.mean([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_orig_std = np.std([acc[:,0] for params, accs in rs.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_orig)),\n",
    "    y1 = var_acc_orig - 0.3*var_acc_orig_std,\n",
    "    y2 = var_acc_orig + 0.3*var_acc_orig_std,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "## Plotting average performance for shuffled ultrametric sequences\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 10), (0.5, 100), (0.5, 1000)]):\n",
    "    \n",
    "    hsv_shfl = tuple([0.6, 1-param_id*0.12, 0.4+param_id*0.12])\n",
    "    var_acc_shfl = np.mean([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_shfl_std = np.std([acc[:,0] for acc in rs.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_shfl)),\n",
    "        y1 = var_acc_shfl - 0.3*var_acc_shfl_std,\n",
    "        y2 = var_acc_shfl + 0.3*var_acc_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "## Plotting average performance for split scenario (two-folds)\n",
    "\n",
    "hsv_tfs_orig = (0.35, 0.8, 0.6)\n",
    "\n",
    "var_acc_tfs_orig = np.mean([acc[:,0] for params, accs in rs_tfs20k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "var_acc_tfs_orig_std = np.std([acc[:,0] for params, accs in rs_tfs20k.var_acc_orig.items() for acc in accs if params[0]==0.50], axis=0)\n",
    "acc_ax.plot(\n",
    "        var_acc_tfs_orig,\n",
    "        marker = '.',\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_orig),\n",
    "        label='T={0:.2f} - Original sequence'.format(0.50)\n",
    "    )\n",
    "acc_ax.fill_between(\n",
    "    x = range(len(var_acc_tfs_orig)),\n",
    "    y1 = var_acc_tfs_orig - var_acc_tfs_orig_std,\n",
    "    y2 = var_acc_tfs_orig + var_acc_tfs_orig_std,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.4\n",
    ")\n",
    "\n",
    "for param_id, params in enumerate([(0.5, 1), (0.5, 100), (0.5, 1000), (0.5, 5000), (0.5, 20000)]):\n",
    "    \n",
    "    hsv_tfs_shfl = tuple([0.35, 0.8-(param_id+1)*0.12, 0.6-(param_id+1)*0.12])\n",
    "    var_acc_tfs_shfl = np.mean([acc[:,0] for acc in rs_tfs20k.var_acc_shfl[params]], axis=0)\n",
    "    var_acc_tfs_shfl_std = np.std([acc[:,0] for acc in rs_tfs20k.var_acc_shfl[params]], axis=0)\n",
    "    \n",
    "    acc_ax.plot(\n",
    "        var_acc_tfs_shfl,\n",
    "        marker=markers[param_id],\n",
    "        markersize=10,\n",
    "        ls = 'none',\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        label='T={0:.2f}, blocksz={1:d} - Shuffled sequence'.format(params[0], params[1])\n",
    "    )\n",
    "    acc_ax.fill_between(\n",
    "        x = range(len(var_acc_tfs_shfl)),\n",
    "        y1 = var_acc_tfs_shfl - var_acc_tfs_shfl_std,\n",
    "        y2 = var_acc_tfs_shfl + var_acc_tfs_shfl_std,\n",
    "        color = hsv_to_rgb(hsv_tfs_shfl),\n",
    "        alpha = 0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(xtick_pos, xtick_labels)\n",
    "\n",
    "##########################################\n",
    "    \n",
    "plt.title('Accuracy as a function of time for original and shuffled sequences', fontsize = 14)\n",
    "\n",
    "box = acc_ax.get_position()\n",
    "acc_ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "acc_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "              fancybox=True, shadow=True, ncol=2,\n",
    "              prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "plt.savefig('out_plots_acc.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.var_acc_shfl.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of training labels along training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "max_time = 50000\n",
    "\n",
    "block_sizes = [1, 100, 200, 400, 800, 1600, 8000]\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    label_hists = {'orig':[], 'shuffled_1600':[]}\n",
    "\n",
    "    total_seq_length = len(rs_rb2[(20, 1600)].train_labels_orig[0.0][:max_time])\n",
    "    label_hists['orig'].extend([\n",
    "        np.histogram(\n",
    "            label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "            range = (0, 32),\n",
    "            bins = 32\n",
    "        )[0] for label_sq in rs_rb2[(20, 1600)].train_labels_orig[0.0]\n",
    "     ])\n",
    "    \n",
    "    #for params in list(rs_rb2.params.keys()):\n",
    "    for shfl_block_sz in [1600]:\n",
    "        \n",
    "        total_seq_length = len(rs_rb2[(20, 1600)].train_labels_shfl[0.0][shfl_block_sz][0][:max_time])\n",
    "        label_hists['shuffled_1600'].extend([\n",
    "            np.histogram(\n",
    "                label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "                range = (0, 32),\n",
    "                bins = 32\n",
    "            )[0] for label_sq in rs_rb2[(20, 1600)].train_labels_shfl[0.0][shfl_block_sz]\n",
    "        ])\n",
    "      \n",
    "    label_hist_tot = {}\n",
    "    label_hist_tot['orig'] = (1/np.sum(label_hists['orig']))*np.sum(label_hists['orig'], axis=0)\n",
    "    label_hist_tot['shuffled_1600'] = (1/np.sum(label_hists['shuffled_1600']))*np.sum(label_hists['shuffled_1600'], axis=0)\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['orig'],\n",
    "        color = 'g',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for original sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['shuffled_1600'],\n",
    "        bottom = label_hist_tot['orig'],\n",
    "        color = 'b',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for T=0.4, shuffled sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.set_title(\"Distribution of observed labels at example #{0:d}\".format((hist_id+1)*(total_seq_length//n_hists)))\n",
    "\n",
    "    acc_ax.set_ylim(0, 0.4)\n",
    "        \n",
    "    acc_ax.legend()\n",
    "    plt.savefig('out_plots_labels_dstr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rs_rb2[(20, 1600)].train_labels_orig[0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "max_time = 50000\n",
    "\n",
    "block_sizes = [1, 100, 200, 400, 800, 1600, 8000]\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    label_hists = {'orig':[], 'shuffled_1600': []}\n",
    "\n",
    "    total_seq_length = len(rs.train_labels_orig[0.4][0][:max_time])\n",
    "    label_hists['orig'].extend([\n",
    "        np.histogram(\n",
    "            label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "            range = (0, 32),\n",
    "            bins = 32\n",
    "        )[0] for label_sq in rs.train_labels_orig[0.4]\n",
    "     ])\n",
    "    \n",
    "    #for params in list(rs.params.keys()):\n",
    "    for shfl_block_sz in [1600]:\n",
    "        total_seq_length = len(rs.train_labels_shfl[0.4][shfl_block_sz][0][:max_time])\n",
    "        label_hists['shuffled_1600'].extend([\n",
    "            np.histogram(\n",
    "                label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "                range = (0, 32),\n",
    "                bins = 32\n",
    "            )[0] for label_sq in rs.train_labels_shfl[0.4][shfl_block_sz]\n",
    "        ])\n",
    "      \n",
    "    label_hist_tot = {0.4: [], 0.65: []}\n",
    "    label_hist_tot['orig'] = (1/np.sum(label_hists['orig']))*np.sum(label_hists['orig'], axis=0)\n",
    "    label_hist_tot['shuffled_1600'] = (1/np.sum(label_hists['shuffled_1600']))*np.sum(label_hists['shuffled_1600'], axis=0)\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['orig'],\n",
    "        color = 'g',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for original sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['shuffled_1600'],\n",
    "        color = 'b',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for T=0.4, shuffled sequence\"\n",
    "    )\n",
    "\n",
    "    acc_ax.set_ylim(0, 0.4)\n",
    "        \n",
    "    acc_ax.legend()\n",
    "    plt.savefig('out_plots_labels_dstr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted class distribution as function of test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(res_set, T, block_size, n_plots=10):\n",
    "\n",
    "    cls_dstr_fig = plt.figure(figsize=(18,18*n_plots//10))\n",
    "\n",
    "    n_tests = int(res_set.params[T][0]['Number of tests'])\n",
    "\n",
    "    for test_run_q in range(n_plots): #rs.params['test_nbr'] or whatever\n",
    "\n",
    "        cls_dstr_ax = plt.subplot(n_plots//2,2,test_run_q+1)\n",
    "        test_run_id = int((test_run_q/n_plots)*n_tests)\n",
    "        \n",
    "        var_pred_orig = np.mean([pred[test_run_id,0] for pred in res_set.var_pred_orig[T]], axis=0)\n",
    "        # res_set.var_pred_orig[0.4][0][0][0]\n",
    "        var_pred_shfl = np.mean([pred[test_run_id,0] for pred in res_set.var_pred_shfl[T][block_size]], axis=0)\n",
    "        \n",
    "        cls_dstr_ax.bar(\n",
    "            [k - 0.2 for k in range(32)],\n",
    "            var_pred_orig,\n",
    "            color = 'b',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        cls_dstr_ax.bar(\n",
    "            [k + 0.2 for k in range(32)],\n",
    "            var_pred_shfl,\n",
    "            color = 'r',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        n_training_examples_seen = int(((test_run_id+1) / n_tests)*seq_length)\n",
    "        plt.title('Distribution of predicted classes within test batch after training on {0:d} examples'.format(n_training_examples_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(rs, 0.4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(rs, 0.4, 1600, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
