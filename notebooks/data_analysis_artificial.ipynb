{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrametric benchmark for continual learning - Data analysis - Artifical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to launch computation on random blocks sequences\n",
    "# python3 main.py -v --dataset artificial --data_tree_depth 5 --data_seq_size 200 --seqlength 200000 --seqtype random_blocks2 --split_length 1000  --nbrtest 200 --nnarchi FCL --hidden_sizes 20 -T 0.4 0.4 0.4 0.4 0.4 0.4 --blocksz 1 100 200 500 1000 2000 4000 6000 8000 10000 20000\n",
    "\n",
    "# Command to launch£ computation on ultrametric sequences\n",
    "# python3 main.py -v --dataset artificial --data_tree_depth 5 --data_seq_size 200 --seqlength 200000 --seqtype ultrametric --nbrtest 200 --nnarchi FCL --hidden_sizes 20 -T 0.4 0.4 0.4 0.4 0.4 0.4 --blocksz 1 100 200 500 1000 2000 4000 6000 8000 10000 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyze the results from such simulations, loading them into ResultSet instances and using methods from data_loader.py for vizualization.<br>\n",
    "Some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Tahoma']\n",
    "\n",
    "import os, sys, ast, pdb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "paths = utils.get_project_paths()\n",
    "\n",
    "## PARAMETERS COMMON TO ALL SIMULATIONS ##\n",
    "seq_length = 300000\n",
    "n_tests = 300\n",
    "T = 0.4\n",
    "\n",
    "import result_loader as ld\n",
    "\n",
    "n_batches = 10\n",
    "lr=0.01\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "artificial_seq_len = 200\n",
    "\n",
    "## LOADING MAPPER FILE ##\n",
    "with open(paths['simus']+'simu_mapping_compact.txt', 'r', encoding='utf-8') as filenames:\n",
    "    filenames_dct_txt = filenames.read().replace('\\n', '')\n",
    "    \n",
    "sim_directory = ast.literal_eval(filenames_dct_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading result sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING RESULT SETS - DEPTH 5 - 32 CLASSES\n",
    "\n",
    "dataset = 'artificial_32'\n",
    "nnarchi = 'FCL20'\n",
    "T = 0.4\n",
    "\n",
    "### ULTRAMETRIC GENERATION METHOD, NO SHUFFLING CLASSES\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_um_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraUnmixed8bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (unmixed labels, 8 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio8_noclshfl',\n",
    "    simset_id = T,\n",
    "    hue = 0\n",
    ")\n",
    "rs5_um_um_r8.load_analytics()\n",
    "\n",
    "\n",
    "### ULTRAMETRIC GENERATION METHOD, SHUFFLING CLASSES\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_mx_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraMixed8bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (mixed labels, 8 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio8',\n",
    "    simset_id = T,\n",
    "    hue = 0.12\n",
    ")\n",
    "rs5_um_mx_r8.load_analytics()\n",
    "\n",
    "\n",
    "### RANDOM BLOCKS (PAIRS OF LABELS) GENERATION METHOD\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_mx_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5RbMixed8bits\",\n",
    "    rs_descr=\"Random blocks (paired mixed labels, 8 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio8',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.5\n",
    ")\n",
    "rs5_blck_mx_r8.load_analytics()\n",
    "\n",
    "\n",
    "### RANDOM BLOCKS (PAIRS OF LABELS) GENERATION METHOD\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_um_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5RbUnmixed8bits\",\n",
    "    rs_descr=\"Random blocks (paired unmixed labels, 8 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio8_noclshfl',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.62\n",
    ")\n",
    "rs5_blck_um_r8.load_analytics()\n",
    "\n",
    "\n",
    "### UNIFORM PROBABILITY DISTIRUBTION\n",
    "rs5_unif_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5Unif8bits\",\n",
    "    rs_descr=\"Uniform, 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'uniform',\n",
    "    simset_id = 0.0,\n",
    "    hue = 0\n",
    ")\n",
    "rs5_unif_r8.load_analytics(load_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING RESULT SETS - DEPTH 5 - 32 CLASSES\n",
    "\n",
    "dataset = 'artificial_32'\n",
    "nnarchi = 'FCL20'\n",
    "T = 0.4\n",
    "\n",
    "### ULTRAMETRIC GENERATION METHOD, NO SHUFFLING CLASSES\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_um_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraUnmixed8bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (unmixed labels, 8 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio8_noclshfl',\n",
    "    simset_id = T,\n",
    "    hue = 0\n",
    ")\n",
    "rs5_um_um_r8.load_analytics()\n",
    "\n",
    "## With 20bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_um_r20 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraUnmixed20bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (unmixed labels, 20 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio20_noclshfl',\n",
    "    simset_id = T,\n",
    "    hue = 0.3\n",
    ")\n",
    "rs5_um_um_r20.load_analytics()\n",
    "\n",
    "### ULTRAMETRIC GENERATION METHOD, SHUFFLING CLASSES\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_mx_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraMixed8bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (mixed labels, 8 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio8',\n",
    "    simset_id = T,\n",
    "    hue = 0.12\n",
    ")\n",
    "rs5_um_mx_r8.load_analytics()\n",
    "\n",
    "## With 20bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_um_mx_r20 = ld.ResultSet(\n",
    "    rs_name=\"d5UltraMixed20bits\",\n",
    "    rs_descr=\"Ultrametric depth 5 (mixed labels, 20 bits/lvl)\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'ultrametric_ratio20',\n",
    "    simset_id = T,\n",
    "    hue = 0.42\n",
    ")\n",
    "rs5_um_mx_r20.load_analytics()\n",
    "\n",
    "### RANDOM BLOCKS (PAIRS OF LABELS) GENERATION METHOD\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_mx_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5RbMixed8bits\",\n",
    "    rs_descr=\"Random blocks (paired mixed labels, 8 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio8',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.5\n",
    ")\n",
    "rs5_blck_mx_r8.load_analytics()\n",
    "\n",
    "## With 20bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_mx_r20 = ld.ResultSet(\n",
    "    rs_name=\"d5RbMixed20bits\",\n",
    "    rs_descr=\"Random blocks (paired mixed labels, 20 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio20',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.8\n",
    ")\n",
    "rs5_blck_mx_r20.load_analytics()\n",
    "\n",
    "### RANDOM BLOCKS (PAIRS OF LABELS) GENERATION METHOD\n",
    "## With 8bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_um_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5RbUnmixed8bits\",\n",
    "    rs_descr=\"Random blocks (paired unmixed labels, 8 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio8_noclshfl',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.62\n",
    ")\n",
    "rs5_blck_um_r8.load_analytics()\n",
    "\n",
    "## With 20bits changed at every level down in the ultrametric tree for pattern generation\n",
    "rs5_blck_um_r20 = ld.ResultSet(\n",
    "    rs_name=\"d5RbUnmixed20bits\",\n",
    "    rs_descr=\"Random blocks (paired unmixed labels, 20 bits/lvl), 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'random_blocks2_ratio20_noclshfl',\n",
    "    simset_id = 1000,\n",
    "    hue = 0.87\n",
    ")\n",
    "rs5_blck_um_r20.load_analytics()\n",
    "\n",
    "### UNIFORM PROBABILITY DISTIRUBTION\n",
    "rs5_unif_r8 = ld.ResultSet(\n",
    "    rs_name=\"d5Unif8bits\",\n",
    "    rs_descr=\"Uniform, 32 classes\",\n",
    "    sim_map_dict = sim_directory,\n",
    "    dataset_name = dataset,\n",
    "    nn_config = nnarchi,\n",
    "    seq_type = 'uniform',\n",
    "    simset_id = 0.0,\n",
    "    hue = 0\n",
    ")\n",
    "rs5_unif_r8.load_analytics(load_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.format_paper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks on the content of one of these sequences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbl_distrib_set(rs, save_formats):\n",
    "    print(\"Instantaneous, first 50k iters only...\")\n",
    "    rs.lbl_distrib(max_iter=50000, save_formats=save_formats)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    print(\"Cumulative, first 50k iters only...\")\n",
    "    rs.lbl_distrib(max_iter=50000, cumulative=True, save_formats=save_formats)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    print(\"Instantaneous, whole sequence...\")\n",
    "    rs.lbl_distrib(save_formats=save_formats)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    print(\"Cumulative, whole sequence...\")\n",
    "    rs.lbl_distrib(save_formats=save_formats, cumulative=True)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lbl_distrib_set(rs5_um_um_r8, save_formats=['svg', 'pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lbl_distrib_set(rs5_blck_mx_r8, save_formats=['svg', 'pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs5_um_um_r8.lbl_history([0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs5_um_um_r8.lbl_history([0.4], shuffled_blocksz=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs5_um_mx_r8.lbl_history([0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs5_um_mx_r8.lbl_history([0.4], shuffled_blocksz=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_um_mx_r8.lbl_history([0.4], shuffled_blocksz=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_um_mx_r8.lbl_history([0.4], shuffled_blocksz=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs5_blck_mx_r8.lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs5_blck_mx_r8.lbl_history([0.0], shuffled_blocksz=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots classification performance as a function of the number of epochs.\n",
    "We are splitting the plots between small block sizes (for which ultrametric and random block sequences are expected to have qualitatively the same behavior), and large block sequences corresponding to temporal correlations that only exist in the ultrametric sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5_sm_splt_sizes = (1, 200, 500, 1000)\n",
    "d5_lg_splt_sizes = (1000, 2000, 8000, 20000, 40000, 80000)\n",
    "d5_all_splt_sizes = (1, 200, 500, 1000, 2000, 8000, 20000, 40000, 80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20bits/lvl\n",
    "Ultrametric vs random blocks, shuffled classes, 20bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r20, rs_altr=rs5_blck_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r20, rs_altr=rs5_blck_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultrametric shuffled vs ultrametric unshuffled classes, 20bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r20, rs_altr=rs5_um_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r8, rs_altr=rs5_um_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random blocks shuffled vs random blocks unshuffled classes, 20bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_blck_um_r20, rs_altr=rs5_blck_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_blck_um_r20, rs_altr=rs5_blck_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8bits/lvl\n",
    "Ultrametric vs random blocks, shuffled classes, 8bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r8, rs_altr=rs5_blck_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r8, rs_altr=rs5_blck_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultrametric shuffled vs ultrametric unshuffled classes, 8bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r8, rs_altr=rs5_um_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r8, rs_altr=rs5_um_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random blocks shuffled vs random blocks unshuffled classes, 8bits/lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_blck_um_r8, rs_altr=rs5_blck_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_blck_um_r8, rs_altr=rs5_blck_mx_r8, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing different bit-flipping ratios, all other things being equal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r8, rs_altr=rs5_um_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_mx_r8, rs_altr=rs5_um_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r8, rs_altr=rs5_um_um_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r8, rs_altr=rs5_um_um_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_lg_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_blck_mx_r8, rs_altr=rs5_blck_mx_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "\trs=rs5_um_um_r20, rs_altr=rs5_blck_um_r20, rs_unif=rs5_unif_r8,\n",
    "\tseq_length=seq_length, n_tests=n_tests, blocks=d5_sm_splt_sizes,\n",
    "\tsave_formats=['svg', 'pdf']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the catastrophic forgetting score. For a clear definition of this score, please see figure 3 among the figures that I have shared.<br>\n",
    "Below is a plot of the loss in classification performance between the actual performance curve and the performance curve of the network on an analog sequence where labels where shuffled with a block size of 1, so that only exploration and the imbalance between classes can limit performance. What we measure is thus the effect of catastrophic forgetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umum5_r8_avg_cf, umum5_r8_avg_cf_std, umum5_r8_init_cf, umum5_r8_init_cf_std = ld.load_cf_set(rs5_um_um_r8, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "ummx5_r8_avg_cf, ummx5_r8_avg_cf_std, ummx5_r8_init_cf, ummx5_r8_init_cf_std = ld.load_cf_set(rs5_um_mx_r8, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "\n",
    "blck5mx_r8_avg_cf, blck5mx_r8_avg_cf_std, blck5mx_r8_init_cf, blck5mx_r8_init_cf_std = ld.load_cf_set(rs5_blck_mx_r8, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "blck5um_r8_avg_cf, blck5um_r8_avg_cf_std, blck5um_r8_init_cf, blck5um_r8_init_cf_std = ld.load_cf_set(rs5_blck_um_r8, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "\n",
    "#umum5_r20_avg_cf, umum5_r20_avg_cf_std, umum5_r20_init_cf, umum5_r20_init_cf_std = ld.load_cf_set(rs5_um_um_r20, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "#ummx5_r20_avg_cf, ummx5_r20_avg_cf_std, ummx5_r20_init_cf, ummx5_r20_init_cf_std = ld.load_cf_set(rs5_um_mx_r20, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "\n",
    "#blck5mx_r20_avg_cf, blck5mx_r20_avg_cf_std, blck5mx_r20_init_cf, blck5mx_r20_init_cf_std = ld.load_cf_set(rs5_blck_mx_r20, d5_all_splt_sizes, save_formats=['svg', 'pdf'])\n",
    "#blck5um_r20_avg_cf, blck5um_r20_avg_cf_std, blck5um_r20_init_cf, blck5um_r20_init_cf_std = ld.load_cf_set(rs5_blck_um_r20, d5_all_splt_sizes, save_formats=['svg', 'pdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the catastrophic forgetting score as the area under the previous curves.<br>\n",
    "We can plot this score as a function of the shuffle size: take the original sequence, shuffle it continuously using blocks of a given size, and measure the CFS using the sequence where imbalance is the onl limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf5_sets_r8 = [\n",
    "    {\n",
    "        'rs': rs5_um_um_r8,\n",
    "        'avg_cf': umum5_r8_avg_cf,\n",
    "        'avg_cf_std': umum5_r8_avg_cf_std,\n",
    "        'init_cf': umum5_r8_init_cf,\n",
    "        'init_cf_std': umum5_r8_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_um_mx_r8,\n",
    "        'avg_cf': ummx5_r8_avg_cf,\n",
    "        'avg_cf_std': ummx5_r8_avg_cf_std,\n",
    "        'init_cf': ummx5_r8_init_cf,\n",
    "        'init_cf_std': ummx5_r8_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_blck_um_r8,\n",
    "        'avg_cf': blck5um_r8_avg_cf,\n",
    "        'avg_cf_std': blck5um_r8_avg_cf_std,\n",
    "        'init_cf': blck5um_r8_init_cf,\n",
    "        'init_cf_std': blck5um_r8_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_blck_mx_r8,\n",
    "        'avg_cf': blck5mx_r8_avg_cf,\n",
    "        'avg_cf_std': blck5mx_r8_avg_cf_std,\n",
    "        'init_cf': blck5mx_r8_init_cf,\n",
    "        'init_cf_std': blck5mx_r8_init_cf_std\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf5_sets_r20 = [\n",
    "    {\n",
    "        'rs': rs5_um_um_r20,\n",
    "        'avg_cf': umum5_r20_avg_cf,\n",
    "        'avg_cf_std': umum5_r20_avg_cf_std,\n",
    "        'init_cf': umum5_r20_init_cf,\n",
    "        'init_cf_std': umum5_r20_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_um_mx_r20,\n",
    "        'avg_cf': ummx5_r20_avg_cf,\n",
    "        'avg_cf_std': ummx5_r20_avg_cf_std,\n",
    "        'init_cf': ummx5_r20_init_cf,\n",
    "        'init_cf_std': ummx5_r20_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_blck_mx_r20,\n",
    "        'avg_cf': blck5mx_r20_avg_cf,\n",
    "        'avg_cf_std': blck5mx_r20_avg_cf_std,\n",
    "        'init_cf': blck5mx_r20_init_cf,\n",
    "        'init_cf_std': blck5mx_r20_init_cf_std\n",
    "    },\n",
    "    {\n",
    "        'rs': rs5_blck_um_r20,\n",
    "        'avg_cf': blck5um_r20_avg_cf,\n",
    "        'avg_cf_std': blck5um_r20_avg_cf_std,\n",
    "        'init_cf': blck5um_r20_init_cf,\n",
    "        'init_cf_std': blck5um_r20_init_cf_std\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.plot_cf_profile(cf5_sets_r8, method='mean', x_origpos=8.5e4, var_scale=0.5, ylog=True, save_formats=['svg', 'pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.plot_cf_profile(cf5_sets_r20, method='mean', x_origpos=8.5e4, var_scale=0.5, ylog=True, save_formats=['svg, pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blck5_r20um_avg_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.plot_cf_profile(cf7_sets, method='mean', x_origpos=2.5e4, var_scale=0.5, ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.plot_cf_profile(cf5v7_sets, method='mean', x_origpos=2.5e4, var_scale=0.5, ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the rest of the notebook contains older material, you can disregard what follows except you have to output the distribution of labels as function of the number of epochs (I need to rewrite some of this code though)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_origpos = 50000\n",
    "\n",
    "fig_mean_cfs = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "ax_mean_cfs = plt.subplot(111)\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_ultra,\n",
    "    ls = 'solid',\n",
    "    linewidth=3,\n",
    "    marker = '+',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    label = 'Ultrametric sequence'\n",
    ")\n",
    "ax_mean_cfs.set_xticks(xtick_pos, xtick_labels)\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = xtick_pos,\n",
    "    y1 = [avg_cf_ultra[k] - var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    y2 = [avg_cf_ultra[k] + var_scale*avg_cf_ultra_std[k] for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_ultra_orig,\n",
    "    marker = '+',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_orig)\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = [x_origpos],\n",
    "    y1 = [cfmean_ultra_orig - avg_cf_ultra_std[0]],\n",
    "    y2 = [cfmean_ultra_orig + avg_cf_ultra_std[0]],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    xtick_pos,\n",
    "    mean_cfs_rb,\n",
    "    ls = '--',\n",
    "    linewidth=3,\n",
    "    marker = 'x',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    label = 'Random split sequence'\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = xtick_pos,\n",
    "    y1 = [avg_cf_randsplit[k] - var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    y2 = [avg_cf_randsplit[k] + var_scale*avg_cf_randsplit_std[k] for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "ax_mean_cfs.plot(\n",
    "    x_origpos,\n",
    "    cfmean_rb_orig,\n",
    "    marker = 'x',\n",
    "    markersize = 20,\n",
    "    markeredgewidth = 4,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig)\n",
    ")\n",
    "ax_mean_cfs.fill_between(\n",
    "    x = [x_origpos],\n",
    "    y1 = [cfmean_rb_orig - avg_cf_randsplit_std[0]],\n",
    "    y2 = [cfmean_rb_orig + avg_cf_randsplit_std[0]],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "# Plot formatting for figure 4 of paper\n",
    "\n",
    "#xtick_pos = [k for k in xtick_pos] + [x_origpos]\n",
    "#xtick_labels = [str(k) for k in xtick_pos] + [25000]\n",
    "ax_mean_cfs.set_xticks(xtick_pos)\n",
    "ax_mean_cfs.set_xticklabels(xtick_labels)\n",
    "\n",
    "plt.title('Per-label loss in classification performance as a function of shuffle block size', fontsize = 18)\n",
    "\n",
    "ax_mean_cfs.legend(fancybox=True, shadow=True, prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Average per-label loss from CF (%)', fontsize=16)\n",
    "\n",
    "fig_mean_cfs.tight_layout(pad=10.0)\n",
    "\n",
    "ax_mean_cfs.hlines(y=cfmean_ultra_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_orig))\n",
    "ax_mean_cfs.hlines(y=cfmean_rb_orig, xmin=0, xmax=1.1*x_origpos, linestyles=':', linewidth=3, color = hsv_to_rgb(hsv_tfs_orig))\n",
    "ax_mean_cfs.vlines(x=30000, ymin=-0.1, ymax=1)\n",
    "\n",
    "ax_mean_cfs.set_xscale(\"log\")\n",
    "\n",
    "for tick in ax_mean_cfs.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "    tick.label.set_rotation('vertical')\n",
    "    \n",
    "for tick in ax_mean_cfs.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(14) \n",
    "\n",
    "ax_mean_cfs.set_xlim(0, 1.1*x_origpos)\n",
    "ax_mean_cfs.set_ylim(-0.1, 0.8)\n",
    "\n",
    "# Saving figure\n",
    "\n",
    "plt.savefig('out_plots_cfscore_avg_logscale.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore_avg_logscale.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in sorted(avg_cf_ultra.keys()) if k>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,len(splt_sizes_rb.keys())*12))\n",
    "cf_blsz_ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(\n",
    "    [k for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    [init_cf_ultra[k] for k in sorted(init_cf_ultra.keys()) if k!=1],\n",
    "    ls = 'solid',\n",
    "    linewidth=3,\n",
    "    marker = '+',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    label = 'Ultrametric sequence'\n",
    ")\n",
    "cf_blsz_ax.fill_between(\n",
    "    x = [k for k in sorted(avg_cf_ultra.keys()) if k>0],\n",
    "    y1 = [init_cf_ultra[k] - var_scale*init_cf_ultra_std[k] for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    y2 = [init_cf_ultra[k] + var_scale*init_cf_ultra_std[k] for k in sorted(init_cf_ultra.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [k for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    [init_cf_randsplit[k] for k in sorted(init_cf_randsplit.keys()) if k!=1],\n",
    "    ls = '--',\n",
    "    linewidth=3,\n",
    "    marker = 'x',\n",
    "    markersize = 15,\n",
    "    markeredgewidth = 3,\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    label = 'Random split sequence'\n",
    ")\n",
    "cf_blsz_ax.fill_between(\n",
    "    x = [k for k in sorted(avg_cf_randsplit.keys()) if k>0],\n",
    "    y1 = [init_cf_randsplit[k] - var_scale*init_cf_randsplit_std[k] for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    y2 = [init_cf_randsplit[k] + var_scale*init_cf_randsplit_std[k] for k in sorted(init_cf_randsplit.keys()) if k>0],\n",
    "    color = hsv_to_rgb(hsv_tfs_orig),\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "plt.title('Per-label loss in classification performance as a function of shuffle block size', fontsize = 18)\n",
    "\n",
    "cf_blsz_ax.legend(fancybox=True, shadow=True, prop={'size': 16})\n",
    "\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Average per-label loss from CF (%)', fontsize=16)\n",
    "\n",
    "fig.tight_layout(pad=10.0)\n",
    "plt.savefig('out_plots_cfscore_init.svg', format='svg')\n",
    "plt.savefig('out_plots_cfscore_init.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of training labels along training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "max_time = 50000\n",
    "\n",
    "block_sizes = [1, 100, 200, 400, 800, 1600, 8000]\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    label_hists = {'orig':[], 'shuffled_1600':[]}\n",
    "\n",
    "    total_seq_length = len(rs_rb2[(20, 1600)].train_labels_orig[0.0][:max_time])\n",
    "    label_hists['orig'].extend([\n",
    "        np.histogram(\n",
    "            label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "            range = (0, 32),\n",
    "            bins = 32\n",
    "        )[0] for label_sq in rs_rb2[(20, 1600)].train_labels_orig[0.0]\n",
    "     ])\n",
    "    \n",
    "    #for params in list(rs_rb2.params.keys()):\n",
    "    for shfl_block_sz in [1600]:\n",
    "        \n",
    "        total_seq_length = len(rs_rb2[(20, 1600)].train_labels_shfl[0.0][shfl_block_sz][0][:max_time])\n",
    "        label_hists['shuffled_1600'].extend([\n",
    "            np.histogram(\n",
    "                label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "                range = (0, 32),\n",
    "                bins = 32\n",
    "            )[0] for label_sq in rs_rb2[(20, 1600)].train_labels_shfl[0.0][shfl_block_sz]\n",
    "        ])\n",
    "      \n",
    "    label_hist_tot = {}\n",
    "    label_hist_tot['orig'] = (1/np.sum(label_hists['orig']))*np.sum(label_hists['orig'], axis=0)\n",
    "    label_hist_tot['shuffled_1600'] = (1/np.sum(label_hists['shuffled_1600']))*np.sum(label_hists['shuffled_1600'], axis=0)\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['orig'],\n",
    "        color = 'g',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for original sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['shuffled_1600'],\n",
    "        bottom = label_hist_tot['orig'],\n",
    "        color = 'b',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for T=0.4, shuffled sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.set_title(\"Distribution of observed labels at example #{0:d}\".format((hist_id+1)*(total_seq_length//n_hists)))\n",
    "\n",
    "    acc_ax.set_ylim(0, 0.4)\n",
    "        \n",
    "    acc_ax.legend()\n",
    "    plt.savefig('out_plots_labels_dstr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rs_rb2[(20, 1600)].train_labels_orig[0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hists = 10\n",
    "max_time = 50000\n",
    "\n",
    "block_sizes = [1, 100, 200, 400, 800, 1600, 8000]\n",
    "\n",
    "acc_fig = plt.figure(figsize=(18,n_hists*9))\n",
    "\n",
    "for hist_id in range(n_hists):\n",
    "    acc_ax = plt.subplot(n_hists, 1, 1+hist_id)\n",
    "\n",
    "    label_hists = {'orig':[], 'shuffled_1600': []}\n",
    "\n",
    "    total_seq_length = len(rs.train_labels_orig[0.4][0][:max_time])\n",
    "    label_hists['orig'].extend([\n",
    "        np.histogram(\n",
    "            label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "            range = (0, 32),\n",
    "            bins = 32\n",
    "        )[0] for label_sq in rs.train_labels_orig[0.4]\n",
    "     ])\n",
    "    \n",
    "    #for params in list(rs.params.keys()):\n",
    "    for shfl_block_sz in [1600]:\n",
    "        total_seq_length = len(rs.train_labels_shfl[0.4][shfl_block_sz][0][:max_time])\n",
    "        label_hists['shuffled_1600'].extend([\n",
    "            np.histogram(\n",
    "                label_sq[:(hist_id+1)*(total_seq_length//n_hists)],\n",
    "                range = (0, 32),\n",
    "                bins = 32\n",
    "            )[0] for label_sq in rs.train_labels_shfl[0.4][shfl_block_sz]\n",
    "        ])\n",
    "      \n",
    "    label_hist_tot = {0.4: [], 0.65: []}\n",
    "    label_hist_tot['orig'] = (1/np.sum(label_hists['orig']))*np.sum(label_hists['orig'], axis=0)\n",
    "    label_hist_tot['shuffled_1600'] = (1/np.sum(label_hists['shuffled_1600']))*np.sum(label_hists['shuffled_1600'], axis=0)\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['orig'],\n",
    "        color = 'g',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for original sequence\"\n",
    "    )\n",
    "    \n",
    "    acc_ax.bar(\n",
    "        x = [k-0.1 for k in range(0,32)],\n",
    "        width=0.2,\n",
    "        height = label_hist_tot['shuffled_1600'],\n",
    "        color = 'b',\n",
    "        alpha = 0.5,\n",
    "        label = \"Distribution of sequence labels for T=0.4, shuffled sequence\"\n",
    "    )\n",
    "\n",
    "    acc_ax.set_ylim(0, 0.4)\n",
    "        \n",
    "    acc_ax.legend()\n",
    "    plt.savefig('out_plots_labels_dstr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted class distribution as function of test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(res_set, T, block_size, n_plots=10):\n",
    "\n",
    "    cls_dstr_fig = plt.figure(figsize=(18,18*n_plots//10))\n",
    "\n",
    "    n_tests = int(res_set.params[T][0]['Number of tests'])\n",
    "\n",
    "    for test_run_q in range(n_plots): #rs.params['test_nbr'] or whatever\n",
    "\n",
    "        cls_dstr_ax = plt.subplot(n_plots//2,2,test_run_q+1)\n",
    "        test_run_id = int((test_run_q/n_plots)*n_tests)\n",
    "        \n",
    "        var_pred_orig = np.mean([pred[test_run_id,0] for pred in res_set.var_pred_orig[T]], axis=0)\n",
    "        # res_set.var_pred_orig[0.4][0][0][0]\n",
    "        var_pred_shfl = np.mean([pred[test_run_id,0] for pred in res_set.var_pred_shfl[T][block_size]], axis=0)\n",
    "        \n",
    "        cls_dstr_ax.bar(\n",
    "            [k - 0.2 for k in range(32)],\n",
    "            var_pred_orig,\n",
    "            color = 'b',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        cls_dstr_ax.bar(\n",
    "            [k + 0.2 for k in range(32)],\n",
    "            var_pred_shfl,\n",
    "            color = 'r',\n",
    "            width = 0.3\n",
    "        )\n",
    "\n",
    "        n_training_examples_seen = int(((test_run_id+1) / n_tests)*seq_length)\n",
    "        plt.title('Distribution of predicted classes within test batch after training on {0:d} examples'.format(n_training_examples_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(rs, 0.4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(rs, 0.4, 1600, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.4, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution((0.65, 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
