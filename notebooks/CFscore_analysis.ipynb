{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying catastrophic forgetting in split sequences\n",
    "#### Simon Lebastard - 02/07/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_root = '/home/proprietaire/Documents/Workspace/Jobs/Columbia/ultrametric_benchmark/Ultrametric-benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root)\n",
    "import result_loader as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200000\n",
    "n_batches = 10\n",
    "lr=0.05\n",
    "\n",
    "# Foar artificial ultrametric dataset only\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "artificial_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "with open('Results/simu_mapping_dict.txt', 'r', encoding='utf-8') as filenames:\n",
    "    filenames_dct_txt = filenames.read().replace('\\n', '')\n",
    "    \n",
    "datapaths = ast.literal_eval(filenames_dct_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll loop through the files produced by the ultrametric framework accross temperatures and shuffle block size, and construct dictionnaries indexed by [T, blocksz].\n",
    "We will then use those dicts to create the plots for DARPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load standard packages and find out about the content of each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n",
      "\n",
      "Loading analytics...\n",
      "load_data set to False. Data sequences not loaded.\n",
      "load_atc set to False. Autocorrelations not loaded.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(project_root+'/Results')\n",
    "\n",
    "## Random split (random two-split) scenario - Various lengths ## \n",
    "\n",
    "dataset= 'artificial_32'\n",
    "artificial_seq_len = 200\n",
    "linear_ratio_for_artificial_seq = 8\n",
    "\n",
    "rs_rb2 = {}\n",
    "\n",
    "for hidden_sz in [5, 10, 20, 60, 200]:\n",
    "    dataroot = project_root+'/Results/1toM/' + dataset + '/' + 'FCL'+str(hidden_sz) + '/' + 'random_blocks2_length200000_batches'+str(n_batches)\n",
    "    if 'artificial' in dataset:\n",
    "        dataroot += '_seqlen'+str(artificial_seq_len)+'_ratio'+str(linear_ratio_for_artificial_seq)\n",
    "    for block_sz in [10, 100, 1000, 4000, 8000, 10000]:\n",
    "        rs_rb2[(hidden_sz, block_sz)] = ld.ResultSet_1toM(\n",
    "            dataroot,\n",
    "            datapaths['1toM'][dataset]['FCL'+str(hidden_sz)]['random_blocks2'][(0.05, 8, 200000, block_sz)]\n",
    "        )\n",
    "        rs_rb2[(hidden_sz, block_sz)].load_analytics()\n",
    "      \n",
    "    \n",
    "## Random split (random two-split) scenario combining two frequencies - Various lengths ## \n",
    "\n",
    "rs_rb2_2freq = {}\n",
    "\n",
    "for hidden_sz in [10, 20, 60]:\n",
    "    dataroot = project_root+'/Results/1toM/' + dataset + '/' + 'FCL'+str(hidden_sz) + '/' + 'random_blocks2_2freq_length200000_batches'+str(n_batches)\n",
    "    if 'artificial' in dataset:\n",
    "        dataroot += '_seqlen'+str(artificial_seq_len)+'_ratio'+str(linear_ratio_for_artificial_seq)\n",
    "    for block_sz_couple in [(100, 1000), (100, 10000), (1000, 10000)]:\n",
    "        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = ld.ResultSet_1toM(\n",
    "            dataroot,\n",
    "            datapaths['1toM'][dataset]['FCL'+str(hidden_sz)]['random_blocks2_2freq'][(0.05, 8, 200000, block_sz_couple[0], block_sz_couple[1])]\n",
    "        )\n",
    "        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].load_analytics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_root+\"/plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 10)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 100)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 320)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 1000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 2000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rb2[(20, 10000)].lbl_history([0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = f(t) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[(20, 100)].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[(20, 100)].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[(20, 1000)].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[(20, 1000)].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.get_acc(\n",
    "    T_list = [0.0],\n",
    "    acc_temp_orig = rs_rb2[(20, 10000)].var_acc_orig,\n",
    "    acc_temp_shuffled = {\n",
    "        0.0: {block_sz: rs_rb2[(20, 10000)].var_acc_shfl[0.0][block_sz] for block_sz in [1]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unit = {}\n",
    "cf = {}\n",
    "cf_explr = {}\n",
    "\n",
    "for hidden_sz in [5, 10, 20, 60, 200]:\n",
    "    for block_sz in [10, 100, 1000, 4000, 8000, 10000]:\n",
    "        cf_unit[(hidden_sz,block_sz)] = []\n",
    "        n_seq = len(rs_rb2[(hidden_sz, block_sz)].var_acc_orig[0.0])\n",
    "        cf_at_fullexplr = []\n",
    "        for seq_id in range(n_seq):\n",
    "            _cf, _t_explr = ld.get_cf(\n",
    "                    rs_rb2[(hidden_sz,block_sz)].train_labels_orig[0.0][seq_id],\n",
    "                    rs_rb2[(hidden_sz,block_sz)].var_acc_orig[0.0][seq_id][:,0],\n",
    "                    rs_rb2[(hidden_sz,block_sz)].var_acc_shfl[0.0][1][0][:,0]\n",
    "                )\n",
    "            cf_unit[(hidden_sz,block_sz)].append(_cf)\n",
    "            cf_at_fullexplr.append(_cf[_t_explr])\n",
    "        cf_unit[(hidden_sz,block_sz)] = np.stack(cf_unit[(hidden_sz,block_sz)], axis=1)\n",
    "        cf[(hidden_sz,block_sz)] = np.mean(cf_unit[(hidden_sz,block_sz)], axis=1)\n",
    "        cf_explr[(hidden_sz,block_sz)] = np.mean(np.array(cf_at_fullexplr))\n",
    "    \n",
    "    if hidden_sz in [10, 20, 60]:\n",
    "        for block_sz_couple in [(100, 1000), (100, 10000), (1000, 10000)]:\n",
    "            cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = []\n",
    "            n_seq = len(rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_orig[0.0])\n",
    "            for seq_id in range(n_seq):\n",
    "                cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].append(\n",
    "                    ld.get_cf(\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].train_labels_orig[0.0][seq_id],\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_orig[0.0][seq_id][:,0],\n",
    "                        rs_rb2_2freq[(hidden_sz, block_sz_couple[0], block_sz_couple[1])].var_acc_shfl[0.0][1][0][:,0]\n",
    "                    )\n",
    "                )\n",
    "            cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = np.stack(cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])], axis=1)\n",
    "            cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])][0,:]\n",
    "            cf[(hidden_sz, block_sz_couple[0], block_sz_couple[1])] = np.mean(cf_unit[(hidden_sz, block_sz_couple[0], block_sz_couple[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "cf_ax = plt.subplot(111)\n",
    "for block_sz in [10, 100, 1000, 10000]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz)],\n",
    "        label='Forgetting score - Split size {0:d}'.format(block_sz)\n",
    "    )\n",
    "cf_ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.15),\n",
    "\t\t\t\t\t  fancybox=True, shadow=True, ncol=2,\n",
    "\t\t\t\t\t  prop={'size': 16})\n",
    "plt.title(\"Catastrophic forgetting on split sequences as a function of split sequence length\", fontsize = 14)\n",
    "plt.xlabel('CF score', fontsize=14)\n",
    "plt.ylabel('Iterations', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "cf_ax = plt.subplot(111)\n",
    "\n",
    "for block_sz in [1000, 10000]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz)],\n",
    "        label='Forgetting score - Split size {0:d}'.format(block_sz)\n",
    "    )\n",
    "\n",
    "for block_sz_couple in [(1000, 10000)]:\n",
    "    cf_ax.plot(\n",
    "        cf[(20, block_sz_couple[0], block_sz_couple[1])],\n",
    "        label='Forgetting score - Split size {0:d} x {1:d}'.format(block_sz_couple[0], block_sz_couple[1])\n",
    "    )\n",
    "\n",
    "cf_ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.15),\n",
    "\t\t\t\t\t  fancybox=True, shadow=True, ncol=2,\n",
    "\t\t\t\t\t  prop={'size': 16})\n",
    "plt.title(\"Catastrophic forgetting on split sequences as a function of split sequence length\", fontsize = 14)\n",
    "plt.ylabel('CF score', fontsize=14)\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "\n",
    "n_tests=200\n",
    "seq_length=200000\n",
    "xtick_scale = 25\n",
    "xtick_pos = xtick_scale*np.arange((n_tests//xtick_scale)+1)\n",
    "xtick_labels = int(seq_length/((n_tests//xtick_scale)))*np.arange((n_tests//xtick_scale)+1)\n",
    "plt.xticks(xtick_pos, xtick_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's try to obtain a plot of mean CF score as a function of (hidden_sz, block_sz) for single-frequency signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b4b81516e4401bc225351f5d11133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Catastrophic Forgetting score')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "cf_ax = plt.axes(projection='3d')\n",
    "\n",
    "hidden_sizes = [5, 10, 20, 60, 200]\n",
    "block_sizes = [10, 100, 1000, 4000, 8000, 10000]\n",
    "\n",
    "cf_avg = {}\n",
    "\n",
    "for hidden_sz in hidden_sizes:\n",
    "    for block_sz in block_sizes:\n",
    "        # cf_avg[(hidden_sz, block_sz)] = np.mean(cf[(hidden_sz, block_sz)])\n",
    "        cf_avg[(hidden_sz, block_sz)] = cf_explr[(hidden_sz,block_sz)]\n",
    "    \n",
    "    cf_avg_arr = np.array([cf_avg[(hidden_sz, bs)] for bs in block_sizes])\n",
    "    cf_ax.plot(\n",
    "        hidden_sz*np.ones(len(block_sizes)),\n",
    "        #np.log10(np.array(block_sizes)),\n",
    "        np.array(block_sizes),\n",
    "        cf_avg_arr\n",
    "    )\n",
    "    \n",
    "cf_ax.set_xlabel('Hidden layer size', fontsize=14)\n",
    "cf_ax.set_ylabel('Timescale of sequence', fontsize=14)\n",
    "cf_ax.set_zlabel('Catastrophic Forgetting score', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation plots (computed a posteriori)\n",
    "\n",
    "Let's plot the autocorrelation function to DARPA standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.get_atc(\n",
    "    T_list=[0.4],\n",
    "    n_tests=10,\n",
    "    out_filename='atc_artificial32_T04'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
